{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p datasets\n",
    "%cd datasets\n",
    "! wget -nc https://raw.githubusercontent.com/pablonoya/zigzag-ml/master/datasets/Iris.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clasificaci√≥n Multiclase\n",
    "Cambiamos el nombre porque ¬°tenemos una nueva tarea!, otra vez üòÉ.   \n",
    "Tenemos **tres estrategias** para predecir a cu√°l de las especies de iris pertenece un ejemplo, aplicamos una de ellas a medias (¬øo a tercias?) en el cap√≠tulo anterior, veamos cu√°l es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One vs the Rest\n",
    "La idea es etiquetar **una clase como positiva** y **todas las dem√°s como negativas**, es **una contra el resto**. En el cap√≠tulo anterior distinguimos entre **setosa** y **no-setosa**, esto lo hacemos para todas las clases, entrenando un **clasificador binario distinto** para cada caso.\n",
    "\n",
    "Completa el siguiente c√≥digo para importar los datos üòâ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas ___\n",
    "from sklearn.model_selection import ___\n",
    "import numpy as np\n",
    "\n",
    "np.random.___\n",
    "\n",
    "df = ___.read_csv(\"./datasets/Iris.csv\")\n",
    "y = df[\"___\"]\n",
    "\n",
    "# no necesitamos estas columnas\n",
    "# guardamos las dem√°s en X\n",
    "X = df.drop(columns=['Id', 'Species'])\n",
    "\n",
    "_, _, _, _ = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto no es muy complicado de implementar, pero el objeto `LogisticRegression` ya cuenta con la opci√≥n de usar dicha estrategia, estableciento su par√°metro `multi_class` en `'ovr'`.  \n",
    "El modelo espera que `y` sea un array 1D, por lo que **no es necesario que realicemos el one-hot encoding**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_log = LogisticRegression(multi_class=\"ovr\")\n",
    "model_log.fit(X_train, y_train)\n",
    "\n",
    "# realicemos algunas predicciones\n",
    "X_sample = X_test.sample(5)\n",
    "model_log.predict(X_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Tambi√©n tenemos la implementaci√≥n en `OneVsRestClassifier` de `sklearn.multiclass`, este recibe una **instancia del modelo** que usaremos, por supuesto, debe ser uno de **regresi√≥n log√≠stica**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "model_ovr = OneVsRestClassifier( LogisticRegression() )\n",
    "model_ovr.fit(X_train, y_train)\n",
    "model_ovr.predict(X_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One vs One\n",
    "Entrenamos clasificadores por pares, **uno contra uno** distinguimos setosa de versicolor, setosa de virginica, versicolor de virginica, y as√≠ hasta entrenar todas las posibles combinaciones, siendo en total:\n",
    "\n",
    "$\\dfrac{K (K-1)}{2} $\n",
    "\n",
    "Donde $K$ es el n√∫mero de clases.\n",
    "\n",
    "La ventaja es que cada clasificador se entrena **s√≥lo con los datos que contienen los pares de clases a distinguir**, algunos modelos **no escalan bien con el tama√±o del dataset**, es decir, rinden peor con un dataset m√°s grande.  \n",
    "En estos casos, **es m√°s r√°pido entrenar muchos clasificadores en peque√±os datasets** en lugar de  **pocos clasificadores en datasets m√°s grandes**. \n",
    "\n",
    "Usaremos `OneVsOneClassifier` tambi√©n de `sklearn.multiclass` pues `LogisticRegression` no soporta esta estrategia. Completa para ver la predicci√≥n üò±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "model_ovo = OneVsOneClassifier(LogisticRegression())\n",
    "model_ovo.fit(X_train, y_train)\n",
    "model_ovo.predict(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regresi√≥n log√≠stica multinomial\n",
    "Es una **generalizaci√≥n** de la regresi√≥n log√≠stica, que cubre **m√∫ltiples clases** directamente, eliminando la necesidad de entrenar varios clasificadores binarios.\n",
    "\n",
    "El par√°metro `multiclass` que vimos antes acepta los par√°metros `'auto'`, `'ovr'` y `'multinomial'`, **auto** es la opci√≥n por defecto, y esta selecciona **ovr** si la variable `y` es **binaria**.\n",
    "\n",
    "Como no es nuestro caso, seleccionar√° **multinomial**, por lo que ser√≠a opcional especificarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_multi = LogisticRegression(multi_class='___')\n",
    "model_multi.fit(X_train, y_train)\n",
    "\n",
    "model_multi.predict(X_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regresi√≥n Softmax\n",
    "Esta generalizaci√≥n es tambi√©n conocida como **regresi√≥n Softmax**. Dado un ejemplo $x$, esta calcula primero un puntaje $s_k(x)$ para cada clase $k$\n",
    "\n",
    "$$ s_k(x) = x^T\\theta^{(k)} $$\n",
    "\n",
    "Nota que **cada clase** tiene su propio **vector** $\\theta^{(k)}$. Cada uno se guarda en una fila de la matr√≠z $\\theta$ que est√° repartida en los atributos `coef_` e `intercept_` de nuestro modelo. A diferencia de lo que vimos al implementar el [descenso del gradiente](5_descenso_del_gradiente.ipynb), donde nuestra variable `theta` conten√≠a los coeficientes y el t√©rmino independiente en una sola matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " model_multi.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Una columna por cada feature, una fila por cada clase üòâ\n",
    "\n",
    "Luego se aplica la funci√≥n **softmax** para calcular las probabilidades $\\hat{p}_k$ de que nuestro ejemplo $x$ **pertenezca a una clase $k$** calculando una f√≥rmula usando exponenciales, cada una de estas representan al n√∫mero $e$ elevado a los puntajes $ s_k(x) $ que antes calculamos.\n",
    "\n",
    "$\\hat{p}_k = \\dfrac{\\exp s_k(x)}{\\sum^K_{j=1}\\exp s_j(x)}$\n",
    "\n",
    "Donde $K$ es el n√∫mero total de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(model_multi.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Al final, la predicci√≥n toma en cuenta la clase con **la probabilidad m√°s alta como respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementaci√≥n de sus f√≥rmulas\n",
    "Primero calculemos $s(x)$ como un vector que contega los **puntajes de cada clase**, por lo que tendr√° 3 elementos al ser el resultado de una multiplicaci√≥n de matrices, y no olvidemos sumar los t√©rminos independientes üòâ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Operamos con una matriz de numpy\n",
    "# y guardamos la primera fila\n",
    "X_sample1 = X_sample.to_numpy()[0]\n",
    "\n",
    "s = X_sample1 @ model_multi.coef_.T + model_multi.intercept_\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Luego $p$ como otro vector de tres elementos que contiene las **probabilidades** de que nuestro ejemplo **pertenezca a alguna de las clases** 0, 1 o 2, setosa, versicolor o virginica, respectivamente üòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = np.exp(s) / np.sum(np.exp(s))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finalmente obtenemos a qu√© clase pertenece nuestro ejemplo üòÉ.  \n",
    "Podemos usar `np.argmax` sobre el **vector que conteniene las probabilidades**, y esto nos retorna el **√≠ndice donde se encuentra la probabilidad m√°s alta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clase de nuestro primer ejemplo\n",
    "pred = np.argmax(p)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Es **versicolor**, como nuestros anteriores modelos lo predijeron üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejercicios\n",
    "Intenta predecir **todo** `X_sample`, usando esta implementaci√≥n al final `pred` deber√≠a ser un **array de 5 elementos** con cada una de las clases predichas para cada ejemplo üòâ.    \n",
    "Adem√°s, `s` y `p` deber√≠an ser matrices de 3x5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplaza X_sample1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øAlguna estrategia rendir√° mejor sobre las otras?\n",
    "Compr√∫ebalo evaluando los 3 modelos sobre precision y recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa las m√©tricas, eval√∫a siempre sobre el test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Cada estrategia tiene su momento: **OvR** si el modelo necesitamos algo **estrictamente binario**, **OvO**  si el modelo **no escala bien con la cantidad de datos** y la **regresi√≥n softmax** es una regresi√≥n log√≠stica generalizada üòÉ.\n",
    "\n",
    "Las primeras dos nos dicen que existen **m√°s tipos de modelos de clasificaci√≥n**, pero el pr√≥ximo que veremos usa softmax al final üòÇ pero no por ello es menos interesante, es m√°s, te aseguro que su nombre te despierta inter√©s üß†:\n",
    "\n",
    "Te presento a las [redes neuronales artificiales](10_Redes_neuronales.ipynb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
