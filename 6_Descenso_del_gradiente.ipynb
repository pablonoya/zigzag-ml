{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso del gradiente\n",
    ">Es un algoritmo **iterativo** de **optimizaci√≥n** para encontrar el **m√≠nimo** local de una funci√≥n.\n",
    "\n",
    "Cuando un modelo de machine learning aprende, no es que mejore directamente, en realidad va siendo \"menos malo\".   \n",
    "Para lograr esto definimos una **loss function** tambi√©n llamada *cost function* o **funci√≥n de costo** que mide el **error** de nuestro modelo y encontramos el punto donde este sea **m√≠nimo**, mediante la **gradiente** -de ah√≠ el nombre- un vector de derivadas que apunta al **m√°ximo** de dicha funci√≥n con una pendiente m√°s o menos inclinada dependiendo al error en ese punto.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1000/1*RxU9mwBejyPoxM95_p-gEA.gif\" width=400/>\n",
    "\n",
    "Llegar al m√≠nimo ¬øapuntando al m√°ximo?  \n",
    "Como la idea es ser menos malo, nos **alejamos** del punto **m√°ximo** de la funci√≥n de costo, donde el error es **alto**, caminamos sobre ella dando pasos hacia **atr√°s** hasta alcanzar el punto **m√≠nimo**.\n",
    "\n",
    "Estos puntos de la funci√≥n est√°n determinados por los par√°metros-$m$ y $b$ para la recta- y los datos de entrenamiento, pues comparamos el **modelo** -dado por los datos y los parametros- con los **targets**.\n",
    "\n",
    "Por cada paso un modelo de regresi√≥n lineal cambiar√° m√°s o menos de esta forma:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1280/1*eeIvlwkMNG1wSmj3FR6M2g.gif\" width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci√≥n de costo\n",
    "Esta cambia seg√∫n el modelo que usemos, para las regresiones lineales se usa la diferencia entre predicci√≥n y target elevada al cuadrado, la misma idea de la m√©trica MSE.\n",
    "\n",
    "Podemos ver, en la primera imagen de este cap√≠tulo, que tiene la forma $y = x^2$ que es [convexa](https://es.wikipedia.org/wiki/Funci%C3%B3n_convexa).  \n",
    "Esto significa que tendr√° un m√≠nimo **global** pues no habr√° otro m√≠nimo, que denominar√≠amos local, como podr√≠a suceder con otra funci√≥n m√°s compleja:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Extrema_example_es.svg/1200px-Extrema_example_es.svg.png\" width=350/>\n",
    "\n",
    "La ubicaci√≥n de√± punto **m√≠nimo** de esta funci√≥n ser√° **dependiente de los datos** de entrenamiento, que pueden ser muy diversos, y cambia de lugar si realizamos transformaciones o a√±adimos features. Es estas variaciones que de antemano no sabemos d√≥nde est√° exactamente, ni por d√≥nde empezar a buscarlo.\n",
    "\n",
    "El algoritmo del descenso por el gradiente propone empezar con un punto **cualquiera**, iniciando los valores de los par√°metros al azar, medir el error y **actualizarlos** para disminuir ese error, **iterando** este procedimiento, esto es, **repetirlo varias veces** hasta que nuestro punto tenga el error **m√≠nimo**, momento en que alcanza la **convergencia**. üòÉ\n",
    "\n",
    "Podemos controlar qu√© tanto cambiar√°n los par√°metros con el hiperpar√°metro **learning rate** o ratio de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate\n",
    "Podr√≠amos decir que controla el tama√±o de los pasos para actualizar los par√°metros, pero debemos tener cuidado al definir este hiperpar√°metro.\n",
    "\n",
    "Si el **learning rate** fuera **alto**, el modelo bien podr√≠a converger en **menos iteraciones**, pero si fuese **demasiado alto** dar√≠amos pasos tan grandes que nos pasar√≠amos del punto m√≠nimo, saltando la convergencia ‚òπ.\n",
    "\n",
    "Pero si fuera **bajo**, el modelo tardar√≠a m√°s en converger, aunque con el suficiente tiempo llegar√≠amos al punto m√≠nimo. Lento pero seguro üê¢.\n",
    "\n",
    "<img src=\"https://www.math.purdue.edu/~nwinovic/figures/learning_rates.png\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "Si tuvieramos dos features nuestra funci√≥n de costo ser√≠a en 3D, nuestro objetivo de llegar al punto m√≠nimo se mantiene y se ver√≠a m√°s o menos as√≠:  \n",
    "\n",
    "<img src=\"https://suniljangirblog.files.wordpress.com/2018/12/1-1.gif\" width=350>\n",
    "\n",
    "Pero estas features pueden tener rangos muy **diferentes**, por ejemplo, en nuestro dataset RM tiene un rango diferente a LSTAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, y = load_boston(True)\n",
    "\n",
    "print(f\"Rango RM    {min(X[:, 5])} -  {max(X[:, 5])}\")\n",
    "print(f\"Rango LSTAT {min(X[:, 12])} -  {max(X[:, 12])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto causa que nuestra funci√≥n de costo quede as√≠, vista desde arriba:\n",
    "\n",
    "![features_unscaled](img/5.1.4_features_unscaled.png)\n",
    "\n",
    "Si iniciamos el descenso por uno de los extremos m√°s alejados de esta elipse, nos tomar√° m√°s tiempo llegar al m√≠nimo global que tenemos en el centro, la soluci√≥n es **escalar** las features para que tengamos un c√≠rculo con las features en un rango de (-1, 1) o (0, 1).\n",
    "\n",
    "Escalar al primer rango se conoce como **standarization**, y al segundo como **normalization**. Podemos aplicar ambos con sklearn, generalmente **no** se escala la variable target, el objetivo a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_selected = X[:, [5, 7]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.4)\n",
    "\n",
    "norm = MinMaxScaler()\n",
    "stand = StandardScaler()\n",
    "X_train_norm = norm.fit_transform(X_train)\n",
    "X_train_stand = stand.fit_transform(X_train)\n",
    "\n",
    "print(\"\\t Sin escalar \\t|\\t Normalization \\t|\\t Standarization\")\n",
    "print( np.column_stack((X_train, X_train_norm, X_train_stand))[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que standarization tiene negativos por su rango (-1, 1) tambi√©n tiene la caracter√≠stica de llevar las features a una media de 0, es recomendable usarla cuando nuestros datos siguen una [distribuci√≥n normal](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal), en caso contrario, es recomendable usar normalization.\n",
    "\n",
    "Pero son recomendaciones, es m√°s importante probar y evaluar lo que mejor se ajuste a nuestros datos üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaci√≥n\n",
    "Vimos bastantes conceptos, ¬øverdad? fue porque la idea principal es importante.\n",
    "\n",
    "El algoritmo de este cap√≠tulo permite que machine learning sea machine learning, porque define una serie de pasos para que la m√°quina aprenda de los datos.\n",
    "Para implementarlo debemos definir algunas f√≥rmulas, espec√≠ficas a la regresi√≥n lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci√≥n de costo\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} ( h_\\theta(x^{(i)}) - y^{(i)} )^2$$\n",
    "\n",
    "Donde:\n",
    "+ $h_\\theta(x) = \\theta^T X = \\theta_0 + \\theta_1x_1 + \\cdots + \\theta_nx_n$\n",
    "+ $m$ es la cantidad de datos\n",
    "+ $i$ es el n√∫mero de fila\n",
    "+ $\\theta$ es el vector de par√°metros\n",
    "\n",
    "Es muy parecida a MSE, con la diferencia de que multiplicamos todo por la constante $\\tfrac{1}{2m}$  \n",
    "$h_\\theta(x)$ representa al modelo de regresi√≥n lineal m√∫ltiple, no es necesario incluir $x_0$ porque es igual a 1.  \n",
    "Y almacenamos los par√°metros en el vector $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones vectorizadas\n",
    "Para la computadora, suele ser m√°s eficiente tratar directamente con vectores y matrices, que implementaremos usando **arrays de numpy**, muchas formulas usan una **notaci√≥n vectorizada** como $\\theta^T X$ para las **sumatorias de productos** aprovechando [c√≥mo se calculan](https://www.problemasyecuaciones.com/matrices/multiplicar-matrices-producto-matricial-ejemplos-explicados-propiedades-matriz.html) las **multiplicaciones de matrices**, cuyo requisito es que el n√∫mero de **columnas** de la primera sea **igual** al n√∫mero de **filas** de la segunda, es decir sus **dimensiones** deben ser **(n, k)** y **(k, m)** respectivamente. El resultado ser√° una matriz con dimensiones **(n, m)**. \n",
    "\n",
    "Esto significa que las matrices a multiplicar deben **compartir un mismo n√∫mero**, en nuestro caso multiplicando `theta` por `X` ¬øqu√© numero comparten?\n",
    "\n",
    "`theta` es el vector de features y `X` es la matriz de datos de entrada, cada fila es un dato, y las columnas son... ¬°features! ese es el n√∫mero que comparten üòâ\n",
    "\n",
    "Para multiplicar usaremos el operador `@` porque as√≠ lo defini√≥ numpy, pero debemos ponerlos en el **orden correcto** la operaci√≥n `theta @ X` multiplicar√≠a arrays de `shape` **(f, 1)** y **(m, f)**, as√≠ no cumplimos el requisito.  \n",
    "La f√≥rmula multiplica la traspuesta de theta, implementada como `theta.T`, esto intercambia las dimensiones a **(1, f)** pero tampoco cumplimos el requsito.\n",
    "\n",
    "La soluci√≥n es multiplicar **(m, f)** x **(f, 1)** dando como resultado una matriz de **(m, 1)** igual que y, esto nos permitir√° restar ambos elemento por elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, y, theta):\n",
    "    # el orden correcto (m, f) x (f, 1)\n",
    "    # resultar√° en (m, 1) igual que y\n",
    "    h = X @ theta\n",
    "    \n",
    "    # s√≥lo transcribimos la f√≥rmula, devolver√° un n√∫mero\n",
    "    return 1 / (2*m) * np.sum((h - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente\n",
    "Este es el vector de derivadas de la funci√≥n de costo:\n",
    "\n",
    "$$\\frac{1}{m}\\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n",
    "\n",
    "Donde $x_j^{(i)}$ es una feature en la fila n√∫mero $i$ columna n√∫mero $j$\n",
    "\n",
    "Recuerda que la funci√≥n de costo tiene la forma $x^2$ cuya derivada es $2x$ esto multiplicado por $\\frac{1}{2m}$ resulta en $\\frac{1}{m}$\n",
    "\n",
    "Por su definici√≥n, debemos devolver un vector de shape **(f, 1)** para luego actualizar `theta` usando el **learning rate**, recuerda que tenemos 2 features y el t√©rmino independiente, f = 3 en este caso.\n",
    "\n",
    "Como en la funci√≥n de costo, la operaci√≥n `h - y` tendr√° shape de **(m, 1)**, pero no la elevamos al cuadrado, debemos multiplicarla por X que tiene shape **(m, f)**.\n",
    "\n",
    "Para esto ponemos trasponer `h - y` multiplicando **(1, m) x (m, f)**  \n",
    "o `X` para multiplicar **(f, m) x (m, 1)**, tomaremos esta opci√≥n que resulta en **(f, 1)** como necesitamos üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(X, y, theta):\n",
    "    h = X @ theta\n",
    "    # cambiamos de lugar los t√©rminos\n",
    "    return 1/m * X.T @ (h - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualizaci√≥n\n",
    "Por ultimo es importante utilizar lo que se conoce como la regla de actualizaci√≥n:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha * grad \\text{ (actualizar simult√°neamente $\\theta_j$ para todas las  $j$)}$$\n",
    "\n",
    "Donde $\\alpha$ es el **learning rate** y $j$ es el n√∫mero de feature\n",
    "\n",
    "Simult√°neamente significa **al mismo tiempo** esta nota es importante porque **no debemos volver calcular el gradiente** hasta haber **actualizado todos** los par√°metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\# C√≥digo final\n",
    "Seguro notaste que la implementaci√≥n es un poco diferente a las f√≥rmulas, esto pasa principalmente por las shapes de nuestras variables, y tambi√©n porque resumimos la sumatoria de productos en forma la multiplicaci√≥n de matrices para el caso de la gradiente üòÉ   \n",
    "Por esto es **importante fijarse en las shapes**, en las que tenemos y en las que deseamos lograr, como la gradiente.\n",
    "\n",
    "Primero definamos algunos hiperpar√°metros como **alpha** o el **n√∫mero m√°ximo de iteraciones**.  \n",
    "Usaremos los datos de entrenamiento a los que aplicamos normalization, nos aseguramos que `y` sea una matriz de (m, 1) y a `X` le a√±adiremos una columna de unos, estos representan a $x_0$ para multiplicarlos con theta, que tendr√° 3 elementos iniciados al azar antes de iterar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aseguramos lareproducibilidad:\n",
    "# mismos resultados en cada iteraci√≥n\n",
    "np.random.seed(42)\n",
    "\n",
    "# Este suele ser un valor bajito\n",
    "alpha = 0.001\n",
    "\n",
    "# Tendremos no m√°s de 1000 iteraciones\n",
    "max_iters = 1000\n",
    "\n",
    "# El viejo reshape\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "# n√∫mero de elementos\n",
    "m = len(y_train)\n",
    "\n",
    "# a√±adimos la columna de unos\n",
    "X_train_norm_1 = np.column_stack((np.ones(m), X_train_norm))\n",
    "\n",
    "# empezamos con un vector de n√∫meros aleatorios\n",
    "# tendr√° 3 filas y 1 columna\n",
    "theta = np.random.randn(3, 1)\n",
    "\n",
    "\n",
    "for i in range(max_iters):\n",
    "    # veamos c√≥mo disminuye el costo cada 100 iteraciones\n",
    "    if i % 100 == 0:\n",
    "        costo = loss(X_train_norm_1, y_train, theta)\n",
    "        print(f\"Costo en it. # {i} {costo :.2f}\")\n",
    "        \n",
    "    # primero calculamos el gradiente\n",
    "    # luego actualizamos theta\n",
    "    gradiente = grad(X_train_norm_1, y_train, theta)\n",
    "    theta -= alpha * gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El costo ha bajado, ¬°el modelo ha aprendido! üòÉ\n",
    "\n",
    "Prueba cambiando el **learning rate**, puedes ir en una escala de tres: 0.001, 0.003, 0.01, ...  \n",
    "Mientras sea mayor, necesitar√°s menos **iteraciones** üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La importancia de (transformar) los datos\n",
    "El descenso del gradiente no es lo m√°s importante para que las m√°quinas aprendan, son los **datos** en s√≠, porque se aprende de ellos y el como los transformamos **antes** de entrenar un modelo cambiar√° mucho los resultados que obtengamos, como en la **regresi√≥n polin√≥mica** obtuvimos una **curva** s√≥lo transformando los datos.\n",
    "\n",
    "Esto se conoce como [preprocesamiento](6_preprocesamiento.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
