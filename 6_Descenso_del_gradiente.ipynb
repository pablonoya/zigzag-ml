{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p datasets\n",
    "%cd datasets\n",
    "! wget -nc https://raw.githubusercontent.com/pablonoya/zigzag-ml/master/datasets/housing.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso del gradiente\n",
    "> Es un algoritmo **iterativo** de **optimizaci√≥n** para encontrar el **m√≠nimo local** de una funci√≥n.\n",
    "\n",
    "Cuando un modelo de machine learning aprende, no va mejorando, en realidad, va siendo \"menos malo\" üòé.   \n",
    "Para lograr esto definimos una **_loss function_** tambi√©n llamada *cost function* o **funci√≥n de costo** que mide el **error** de nuestro modelo y utilizamos la **gradiente**, de ah√≠ el nombre del algoritmo, la cual es un vector de derivadas que apunta al **m√°ximo** de dicha funci√≥n con una pendiente que es m√°s o menos inclinada seg√∫n el error que se mida en ese punto üìâ.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1000/1*RxU9mwBejyPoxM95_p-gEA.gif\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llegar al m√≠nimo ¬øapuntando al m√°ximo?  \n",
    "Como la idea es ser menos malo, nos vamos **alejando** del punto **m√°ximo** en la funci√≥n de costo, en este punto, el **error es muy alto**. Caminaremos sobre la funci√≥n de costo **dando pasos hacia atr√°s** hasta alcanzar el punto **m√≠nimo** üö∂.\n",
    "\n",
    "Estos puntos de la funci√≥n est√°n determinados por los par√°metros, $m$ y $b$ en el caso de la recta, y los datos de entrenamiento.  \n",
    "Comparamos el **modelo**, dado por los datos y sus par√°metros, con los **labels**, que deber√≠an ser la respuesta ideal del modelo.\n",
    "\n",
    "Por cada **iteraci√≥n del algoritmo**, un modelo de regresi√≥n lineal cambiar√° m√°s o menos de esta forma:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1280/1*eeIvlwkMNG1wSmj3FR6M2g.gif\" width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci√≥n de costo\n",
    "Esta cambia seg√∫n el modelo que usemos, para las regresiones lineales se usa la diferencia entre predicci√≥n y *label* elevada al cuadrado, como ocurre con la m√©trica MSE üòâ.\n",
    "\n",
    "Esta funci√≥n tiene la forma $y = x^2$, adem√°s es [convexa](https://es.wikipedia.org/wiki/Funci%C3%B3n_convexa).  \n",
    "Lo cual significa que tendr√° un s√≥lo m√≠nimo, al cual denominamos **m√≠nimo global** pues no habr√° otro, que denominar√≠amos **m√≠nimo local** en caso de una funci√≥n m√°s compleja:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Extrema_example_es.svg/1200px-Extrema_example_es.svg.png\" width=400/>\n",
    "\n",
    "La ubicaci√≥n del **punto m√≠nimo** de esta funci√≥n **depender√° de los datos** de entrenamiento, y cambia de lugar si realizamos transformaciones o a√±adimos features.  \n",
    "Debido a estas variaciones, de antemano no sabemos d√≥nde est√° exactamente, ni por d√≥nde empezar a buscarlo üòÖ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteraciones\n",
    "El algoritmo del descenso por el gradiente propone los siguientes pasos :\n",
    "\n",
    "1. **Iniciar los valores de los par√°metros al azar**, lo cual nos pondr√° en un punto cualquiera üòÉ.\n",
    "2. Medir el error en ese punto y **actualizar los par√°metros** para disminuir ese error ‚¨áÔ∏è.\n",
    "3. **Iterar** el paso anterior, esto es, **repetirlo varias un n√∫mero de veces** que le indiquemos üîÅ.\n",
    "4. Muestro modelo tiene el **error m√≠nimo**, lo que denominamos **convergencia** üòâ.\n",
    "\n",
    "El modelo ha aprendido üß†.\n",
    "\n",
    "Y podemos controlar qu√© tanto cambiar√°n los par√°metros mediante el **learning rate** o ratio de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate\n",
    "Podr√≠amos decir que controla el tama√±o de los pasos que damos hacia atr√°s para actualizar los par√°metros, y debemos tener cuidado cuando definimos este hiperpar√°metro ‚ö†Ô∏è.\n",
    "\n",
    "Si el **learning rate** fuera **alto**, el modelo bien podr√≠a converger en **menos iteraciones**, pero si fuese **demasiado alto** dar√≠amos pasos tan grandes que nos pasar√≠amos del punto m√≠nimo, saltando la convergencia ‚òπ.\n",
    "\n",
    "Y si fuera **bajo**, el modelo **tardar√≠a m√°s en converger**, aunque dado el suficiente tiempo llegar√≠amos al punto m√≠nimo.  \n",
    "Lento pero seguro üê¢.\n",
    "\n",
    "<img src=\"https://www.math.purdue.edu/~nwinovic/figures/learning_rates.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaci√≥n\n",
    "Vimos bastantes conceptos, ¬øverdad?, la intuci√≥n es muy importante para pasar a la implementaci√≥n üòÑ.\n",
    "\n",
    "Este algoritmo permite que *machine learning* sea *machine learning*, pues define una serie de pasos para que la m√°quina aprenda de los datos üß†.  \n",
    "Para implementarlo debemos definir algunas f√≥rmulas matem√°ticas, que son espec√≠ficas para la regresi√≥n lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F√≥rmula de la funci√≥n de costo\n",
    "Es muy parecida a MSE, con la diferencia de que multiplicamos todo por la constante $\\tfrac{1}{2m}$  \n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} ( h_\\theta(x^{(i)}) - y^{(i)} )^2$$\n",
    "\n",
    "Donde:\n",
    "+ $m$ es la cantidad de datos.\n",
    "+ $\\theta$ es el vector de par√°metros.\n",
    "+ $i$ es el n√∫mero de la fila en nuestra matriz de datos.\n",
    "+ $h_\\theta(x) = \\theta^T X = \\theta_0 + \\theta_1x_1 + \\cdots + \\theta_nx_n$\n",
    "+ $x^{(i)}$ es una fila de datos.\n",
    "+ $y^{(i)}$ es la etiqueta de esa fila de datos.\n",
    "\n",
    "\n",
    "La hip√≥tesis $h_\\theta(x)$ es equivalente a $\\hat{y}$. Representa al modelo de regresi√≥n lineal, no incluimos $x_0$ porque esta es igual a 1, quedando s√≥lo $\\theta_0$ como el t√©rmino independiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones vectorizadas\n",
    "Para la computadora, suele ser m√°s eficiente tratar directamente con vectores y matrices, que implementaremos usando **arrays de numpy**, muchas formulas usan una **notaci√≥n vectorizada** como $\\theta^T X$ para las **sumatorias de productos** aprovechando [c√≥mo se calculan](https://www.problemasyecuaciones.com/matrices/multiplicar-matrices-producto-matricial-ejemplos-explicados-propiedades-matriz.html) las **multiplicaciones de matrices**, cuyo requisito es que el n√∫mero de **columnas** de la primera sea **igual** al n√∫mero de **filas** de la segunda, es decir sus **dimensiones** deben ser **(n, k)** y **(k, m)** respectivamente. El resultado ser√° una matriz con dimensiones **(n, m)**. \n",
    "\n",
    "Esto significa que las matrices a multiplicar deben **compartir un mismo n√∫mero**, en nuestro caso multiplicando `theta` por `X` ¬øqu√© numero comparten?  \n",
    "`theta` es el vector de features y `X` es la matriz de datos de entrada, cada fila es un dato, y las columnas son... ¬°features!, ambas **comparten el n√∫mero de features** üòâ\n",
    "\n",
    "Para multiplicar usaremos el operador `@` porque as√≠ lo defini√≥ numpy, pero debemos ponerlos en el **orden correcto** la operaci√≥n `theta @ X` multiplicar√≠a arrays de `shape` **(f, 1)** y **(m, f)**, pero as√≠ no cumplimos el requisito ‚òπ.  \n",
    "La f√≥rmula $\\theta^T X$ multiplica la traspuesta de theta, la implementamos como `theta.T`, esto **voltea las dimensiones** de **(f, 1)** a **(1, f)** pero esto tampoco cumple el requsito ‚òπ.\n",
    "\n",
    "La soluci√≥n es multiplicar **(m, f)** x **(f, 1)** dando como resultado una matriz de **(m, 1)** igual a las dimensiones de $y$, esto nos permitir√° luego restarla de la hip√≥tesis elemento por elemento.  \n",
    "Fijarnos en qu√© haremos con el resultado es una buena idea para acomodar nuestras multiplicaciones de matrices, no importa que no sigamos la f√≥rmula tal cual üòâ\n",
    "A menos que terminemos con una forma muy diferente y que no podamos utilizar, como (1, 1) üòÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss(X, y, theta):\n",
    "    # el orden correcto (m, f) x (f, 1)\n",
    "    # resultar√° en (m, 1) igual que y\n",
    "    h = X @ theta\n",
    "    \n",
    "    # s√≥lo transcribimos la f√≥rmula, por la suma devolver√° un n√∫mero\n",
    "    return 1 / (2*m) * np.sum((h - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente\n",
    "Este es el vector de derivadas de la funci√≥n de costo:\n",
    "\n",
    "$$\\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} = \\frac{1}{m} (h_\\theta(X) - Y) X$$\n",
    "\n",
    "Donde $x_j^{(i)}$ es un dato en la fila n√∫mero $i$ columna n√∫mero $j$\n",
    "\n",
    "Recuerda que la funci√≥n de costo tiene la forma $x^2$ cuya derivada es $2x$ este n√∫mero multiplicado por $\\frac{1}{2m}$ cancela la constante a $\\frac{1}{m}$\n",
    "\n",
    "Por su definici√≥n, debemos devolver un vector de shape **(f, 1)** porque usamos la gradiente para actualizar `theta` usando el **learning rate**.\n",
    "\n",
    "Como en la funci√≥n de costo, la operaci√≥n `h - y` tendr√° shape de **(m, 1)**, luego debemos multiplicar este resultado por X que tiene shape **(m, f)**.\n",
    "\n",
    "Para multiplicar, podemos trasponer la resta `h - y`, multiplicando **(1, m) x (m, f)**  \n",
    "o `X` para multiplicar **(f, m) x (m, 1)**, tomaremos esta opci√≥n, pues resulta en **(f, 1)** como necesitamos üòâ\n",
    "\n",
    "Adem√°s eliminamos la sumatoria gracias a la multiplicaci√≥n de matricesüòÉ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(X, y, theta):\n",
    "    h = X @ theta\n",
    "    # cambiamos de lugar los t√©rminos\n",
    "    return 1/m * X.T @ (h - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualizaci√≥n\n",
    "Por ultimo es importante utilizar lo que se conoce como la regla de actualizaci√≥n:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha * grad \\text{ (actualizar simult√°neamente $\\theta_j$ para todas las  $j$)}$$\n",
    "\n",
    "Donde $\\alpha$ es el **learning rate** y $j$ es el n√∫mero de columna\n",
    "\n",
    "Simult√°neamente significa **al mismo tiempo**, esta nota es importante porque **no debemos volver a calcular el gradiente** hasta haber **actualizado antes todos los par√°metros**, pues la misma gradiente depende de los par√°metros üòµ‚Äçüí´."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\# C√≥digo final\n",
    "La implementaci√≥n es un poco diferente a las f√≥rmulas, esto pasa por las shapes de nuestras variables, y porque resumimos la sumatoria de productos en forma la multiplicaci√≥n de matrices para el caso de la gradiente üòÉ.  \n",
    "\n",
    "> Por esto es **importante fijarse en las shapes**, tanto las que tenemos como las que deseamos lograr ‚ö†Ô∏è.\n",
    "\n",
    "Usaremos los datos de entrenamiento que estuvimos usando antes, asegurando que que `y` sea una matriz de (m, 1).  \n",
    "En el caso de `X` le a√±adiremos una columna de unos, estos representan a $x_0$ para multiplicarlos con $\\theta_0$, lo cual resulta en el t√©rmino independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 8.3252],\n",
       "       [1.    , 8.3014],\n",
       "       [1.    , 7.2574],\n",
       "       ...,\n",
       "       [1.    , 1.7   ],\n",
       "       [1.    , 1.8672],\n",
       "       [1.    , 2.3886]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_housing = pd.read_csv('./datasets/housing.csv')\n",
    "data_housing.dropna(inplace=True)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = data_housing['median_income']\n",
    "y = data_housing['median_house_value']\n",
    "\n",
    "# a√±adimos la columna de unos\n",
    "X = np.column_stack((np.ones(len(X)), X))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definamos algunos hiperpar√°metros como **alpha** o el **n√∫mero m√°ximo de iteraciones**.  \n",
    "Tambien definimos `theta` que tendr√° 2 elementos iniciados al azar: nuestra feature y el t√©rmino independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha suele ser un valor bajito\n",
    "alpha = 0.0003\n",
    "\n",
    "# Tendremos 1000 iteraciones\n",
    "max_iters = 1000\n",
    "\n",
    "# empezamos con un vector de n√∫meros aleatorios\n",
    "# tendr√° 2 filas y 1 columna\n",
    "theta = np.random.randn(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces iniciamos con las iteraciones utilizando nuestras funciones de costo y gradiente üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo en it. # 0 27970926073.83\n",
      "Costo en it. # 100 11180501087.93\n",
      "Costo en it. # 200 5954283193.15\n",
      "Costo en it. # 300 4326966880.29\n",
      "Costo en it. # 400 3819672773.89\n",
      "Costo en it. # 500 3660949793.75\n",
      "Costo en it. # 600 3610714879.02\n",
      "Costo en it. # 700 3594251780.51\n",
      "Costo en it. # 800 3588307983.82\n",
      "Costo en it. # 900 3585646982.24\n"
     ]
    }
   ],
   "source": [
    "# n√∫mero de elementos\n",
    "m = len(y_train)\n",
    "\n",
    "# El viejo reshape\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "for i in range(max_iters):\n",
    "    # veamos c√≥mo disminuye el costo cada 100 iteraciones\n",
    "    if i % 100 == 0:\n",
    "        costo = loss(X_train, y_train, theta)\n",
    "        print(f\"Costo en it. # {i} {costo :.2f}\")\n",
    "        \n",
    "    # primero calculamos el gradiente\n",
    "    gradiente = grad(X_train, y_train, theta)\n",
    "    # actualizamos theta, dando el paso atr√°s con la resta\n",
    "    theta -= alpha * gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El costo ha bajado, ¬°el modelo ha aprendido! üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "Prueba cambiando el **learning rate**, puedes ir en una escala de tres: 0.0001, 0.0003, 0.001, ...  \n",
    "Mientras sea mayor, necesitar√°s menos **iteraciones** üòâ pero no te excedas o el modelo no aprender√° ü§Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s√≥lo es un hiperpar√°metro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A√±ade m√°s features y ajusta los hiperpar√°metros, es posible que no llegues a los resultados de sklearn, pero lo importante es que tu costo siempre vaya bajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no te olvides de cambiar la forma de theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La importancia de (transformar) los datos\n",
    "El descenso del gradiente no es lo m√°s importante para que las m√°quinas aprendan, son los **datos**, porque se aprende de ellos üß†.  \n",
    "Y el c√≥mo los **transformemos antes de entrenar un modelo** influir√° en los resultados que obtengamos, como en la **regresi√≥n polin√≥mica** obtuvimos una **curva** s√≥lo transformando los datos.\n",
    "\n",
    "Trabajar con los datos antes del entrenamiento se conoce como [preprocesamiento](6_preprocesamiento.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Feature scaling\n",
    "Si tuvieramos dos features nuestra funci√≥n de costo ser√≠a en 3D, nuestro objetivo de llegar al punto m√≠nimo se mantiene y se ver√≠a m√°s o menos as√≠:  \n",
    "\n",
    "<img src=\"https://suniljangirblog.files.wordpress.com/2018/12/1-1.gif\" width=350>\n",
    "\n",
    "Pero estas features pueden tener rangos muy **diferentes**, por ejemplo, en nuestro dataset RM tiene un rango diferente a LSTAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, y = load_boston(True)\n",
    "\n",
    "print(f\"Rango RM    {min(X[:, 5])} -  {max(X[:, 5])}\")\n",
    "print(f\"Rango LSTAT {min(X[:, 12])} -  {max(X[:, 12])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Esto causa que nuestra funci√≥n de costo quede as√≠, vista desde arriba:\n",
    "\n",
    "![features_unscaled](img/5.1.4_features_unscaled.png)\n",
    "\n",
    "Si iniciamos el descenso por uno de los extremos m√°s alejados de esta elipse, nos tomar√° m√°s tiempo llegar al m√≠nimo global que tenemos en el centro, la soluci√≥n es **escalar** las features para que tengamos un c√≠rculo con las features en un rango de (-1, 1) o (0, 1).\n",
    "\n",
    "Escalar al primer rango se conoce como **standarization**, y al segundo como **normalization**. Podemos aplicar ambos con sklearn, generalmente **no** se escala la variable target, el objetivo a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X_selected = X[:, [5, 7]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.4)\n",
    "\n",
    "norm = MinMaxScaler()\n",
    "stand = StandardScaler()\n",
    "X_train_norm = norm.fit_transform(X_train)\n",
    "X_train_stand = stand.fit_transform(X_train)\n",
    "\n",
    "print(\"\\t Sin escalar \\t|\\t Normalization \\t|\\t Standarization\")\n",
    "print( np.column_stack((X_train, X_train_norm, X_train_stand))[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Podemos ver que standarization tiene negativos por su rango (-1, 1) tambi√©n tiene la caracter√≠stica de llevar las features a una media de 0, es recomendable usarla cuando nuestros datos siguen una [distribuci√≥n normal](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal), en caso contrario, es recomendable usar normalization.\n",
    "\n",
    "Pero son recomendaciones, es m√°s importante probar y evaluar lo que mejor se ajuste a nuestros datos üòâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
