{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p datasets\n",
    "%cd datasets\n",
    "! wget -nc https://raw.githubusercontent.com/pablonoya/zigzag-ml/master/datasets/Iris_mod.csv\n",
    "! wget -nc https://raw.githubusercontent.com/pablonoya/zigzag-ml/master/datasets/housing.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos\n",
    "En el mundo real, los datos que obtengamos pueden ser err√≥neos porque estar√°n incompletos, duplicados o no se podr√°n usar tal cual, porque los algoritmos de *machine learning* usan **s√≥lo n√∫meros** üî¢.  \n",
    "\n",
    "Veremos c√≥mo afrontar este tipo de situaciones con un nuevo dataset, el [Iris Dataset](https://www.kaggle.com/uciml/iris) de kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_iris = pd.read_csv('./datasets/Iris_mod.csv')\n",
    "data_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, tenemos un dataset con las medidas de largo y ancho del s√©palo y el p√©talo de una flor de iris, cuya especie se menciona en la √∫ltima columna.\n",
    "\n",
    "Tambi√©n tenemos la columna \"Id\" pero no es necesaria, as√≠ que vamos a eliminarla con el m√©todo `drop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iris.drop(columns=['Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øCu√°ntas especies tenemos? usemos la funci√≥n `nunique` para contar los valores √∫nicos de la columna \"Species\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iris['Species'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto **ignora** los valores **nulos**, veamos cu√°ntos tenemos en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iris.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucionando valores nulos\n",
    "Tenemos exactamente tres valores nulos en cada columna. ¬øConcidencia? ~~no lo creo~~.  \n",
    "En realidad modifiqu√© el dataset para prop√≥sitos educativos üòÑ y a√±ad√≠ una fila de nulos que podemos verla usando `tail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iris.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos aparecen como **NaN** siglas de *Not a Number* o **No es un N√∫mero**, para tratarlos podemos **eliminar las filas o columnas** que contengan alg√∫n valor nulo o no permitido üòµ.  \n",
    "Otra opci√≥n es **reemplazarlos** con la **media** o la **moda** de toda su columna ü§î.\n",
    "\n",
    "Antes de intentar cualquier soluci√≥n crearemos una **copia** de nuestro data_iris usando `copy` para preservar el original, si no usas copy s√≥lo tendr√°s una referencia al objeto original, como pasa con las listas en Python üêç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_iris.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar filas\n",
    "Es recomendable cuando tenemos **muchos datos y pocos son nulos**, pues no perdemos demasiada informaci√≥n.\n",
    "\n",
    "Usaremos el m√©todo `dropna` que recibe el par√°metro `axis` o eje, que corresponde con la dimensi√≥n, podemos utilizar`0` o `\"index\"` para el caso de las **filas**.\n",
    "La funci√≥n eliminar√° cualquier fila que contenga alg√∫n valor nulo üòµ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar columnas\n",
    "La usamos **si la columna no es importante**, o si **tenemos demasiados valores nulos**, pues no podr√≠amos recuperar informaci√≥n.\n",
    "\n",
    "S√≥lo cambiamos`axis` a `1` o `'columns'` para el caso de las **columnas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_iris.copy()\n",
    "\n",
    "df = df.dropna('columns')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\cdots$  \n",
    "Recuerda siempre que **un s√≥lo nulo basta**  para eliminar **toda** la fila o columna üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reemplazar con la media\n",
    "La media es el promedio de la columna, por supuesto s√≥lo funciona con los valores num√©ricos üî¢.  \n",
    "Debido a esto, exclu√≠mos la columna **Species** usando `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas las filas, de la primera a la pen√∫ltima columna\n",
    "df = data_iris.iloc[:, :-1]\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn tiene el objeto `SimpleImputer` para reemplazar valores, reemplazar√° los nulos por defecto.  \n",
    "S√≥lo debemos indicarle la `strategy` o estrategia para reemplazar los valores, que ser√° `\"mean\"` en este caso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = data_iris.iloc[:, :-1]\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "df_inputed_mean = imp.fit_transform(df)\n",
    "\n",
    "# veamos la √∫ltima fila\n",
    "df_inputed_mean[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que sean los valores correctos usando el m√©todo `mean` sobre el *DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reemplazar con la moda\n",
    "La moda es el valor que m√°s se repite, por lo que podemos usar texto üî°.  \n",
    "Usaremos tambi√©n `SimpleImputer` cambiando la `strategy` a `\"most_frequent\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_iris.copy()\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "df_inputed_mode = imp.fit_transform(df)\n",
    "df_inputed_mode[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos comprobarlo con el m√©todo `mode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas calcul√≥ que los nulos son valores que se repiten, pero `SimpleImputer` tom√≥ los primeros valores no nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valores no num√©ricos\n",
    "Para tratarlos **es necesario codificarlos**, una de las primeras ideas es asignar valores en serie como 1, 2, 3,... a cada especie, pero esto **implica que hay un orden establecido** entre especies.\n",
    "El modelo podr√≠a entender algo como 3 > 2 > 1, aprendiendo que cierta especie es mejor o peor que otra üòÖ.\n",
    "\n",
    "En su lugar debemos indicar que son valores de diferente **categor√≠a** con un c√≥digo que indique algo como\n",
    "> Es Iris setosa y no otra cosa\n",
    "\n",
    "| # | Iris setosa | Otra cosa |\n",
    "|---|-------------|-----------|\n",
    "| 1 |   s√≠   |   no   |\n",
    "| 2 |   s√≠   |   no   |\n",
    "| 3 |   no   |   si   |\n",
    "\n",
    "Tendremos **una columna por categor√≠a**, marcando 1 a la que pertenece y 0 a las dem√°s, esto se conoce como **One-hot encoding** y podemos obtenerla con el m√©todo `get_dummies` de pandas üêº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot = pd.get_dummies(df)\n",
    "df_one_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto actuar√° con todos los valores con el *dtype* `object`, pero tambi√©n puedes tener un dataset con **categor√≠as en forma de n√∫meros**, como dec√≠amos antes 1, 2, 3, ...  \n",
    "Aseg√∫rate de informarte sobre las columnas del dataset, podr√≠as encontrar esta informaci√≥n en la [fuente](https://www.kaggle.com/uciml/iris) de cada dataset üòâ.\n",
    "\n",
    "Puedes verificar los `dtypes` de cada columna con ese atributo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n podemos usar `OneHotEncoder` de sklearn, pero s√≥lo enviaremos las columnas que queramos transformar y no admite que los datos tengan valores nulos.  \n",
    "Por defecto retorna una [matriz dispersa](https://es.wikipedia.org/wiki/Matriz_dispersa) pero podemos cambiarlo cambiando el par√°metro `sparse` a falso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# s√≥lo la √∫ltima columna\n",
    "df_species = df_inputed_mode[:, [-1]]\n",
    "\n",
    "one_hot = OneHotEncoder(sparse=False)\n",
    "df_one_hot = one_hot.fit_transform(df_species)\n",
    "df_one_hot[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tuvi√©ramos s√≥lo dos categor√≠as **no es necesario agregar dos columnas**, los valores 0 y 1 ya indican la **presencia o ausencia** de la feature üòÑ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "¬øQu√© otras estrategias pueden ser √∫tiles? prueba las que tiene `SimpleImputer` de sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisa la documentaci√≥n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza alguna estrategia con el dataset de casas, los datos nulos estaban en \"total_bedrooms\", eval√∫a qu√© tanto mejora el modelo utilizando s√≥lo esa feature y la variable objetivo \"median_house_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_bedrooms es una cantidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con todo lo aprendido ya vamos dominando las bases del machine learning üòâ.  \n",
    "Es m√°s, ahora la m√°quina puede aprender a **distinguir categor√≠as o clases** ü§Ø.\n",
    "\n",
    "> Ten las med√≠das de s√©palo, p√©talo y dime ¬øes setosa u otra cosa?  \n",
    "\n",
    "$\\cdots$  \n",
    "Responder√°, cuando aprenda [clasificaci√≥n](8_Clasificacion.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
