{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Hola mundo! del machine learning\n",
    "Considero que el [hola mundo](https://es.wikipedia.org/wiki/Hola_mundo) del machine learning es la [regresión lineal](https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal).\n",
    "\n",
    "El **modelo** resultante será la recta que mejor se **ajuste** a nuestro **dataset** o conjunto de datos, sklearn tiene [algunos](https://scikit-learn.org/stable/datasets/index.html), elegiremos el de **Boston house prices**, que tiene datos y valores (en miles) de varias viviendas en los suburbios... de Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¡venga, dataset!\n",
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features en X, targets en y, así nombraremos las variables desde ahora.\n",
    "\n",
    "La lista completa de las 13 features está [aquí](https://scikit-learn.org/stable/datasets/index.html#boston-house-prices-dataset) pero sólo usaremos la sexta **RM** promedio de habitaciones por vivienda.\n",
    "\n",
    "Veamos cómo se relaciona con el precio gracias a una [gráfica de dispersion](https://es.wikipedia.org/wiki/Diagrama_de_dispersi%C3%B3n) realizada con [matplotlib](https://matplotlib.org/), una librería para graficar datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seleccionamos todas las filas, sexta columna\n",
    "X_RM = X[:, 5]\n",
    "X_RM = X_RM.reshape(-1, 1)\n",
    "\n",
    "plt.scatter(X_RM, y)\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.title(\"Relación entre RM y Valor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, vemos una relación directamente proporcional: a más habitaciones, mayor costo.  \n",
    "También vemos muchos puntos en la parte superior, esto parece indicar que los precios mayores a 50 mil han sido truncados a 50 mil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ajustamos la recta\n",
    "model = LinearRegression()\n",
    "model.fit(X_RM, y)\n",
    "\n",
    "print(f\"Los parámetros obtenidos son: {model.coef_[0] :.2f} y {model.intercept_ :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pendiente es positiva, esto confirma la relación directamente proporcional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando el modelo\n",
    "Con el modelo entrenado, podemos **estimar** o **predecir** el valor de todas las viviendas, sólo debemos llamar al método `predict`. Este usará internamente los parámetros `coef_` e `intercept` para la ecuación que ya conocemos.\n",
    "\n",
    "Para evaluar qué tan bien predice el modelo comparemos la primera predicción con el valor real de la primera vivienda. Los valores reales son los targets, recuerda que están en y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = model.predict(X_RM)\n",
    "\n",
    "# comparemos con el valor real\n",
    "print(f\"El valor real es {y[0]}, y según el modelo es {predicted_values[0] :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una diferencia de -1.518 para esta vivienda, el modelo estima que el valor debe ser más alto porque la recta está encima del valor real, por supuesto, la diferencia será positiva de lo contrario y será mayor mientras más lejos esté de la recta.\n",
    "\n",
    "Veamos cómo quedó la recta, tomaremos los valores máximo y mínimo de X, luego aplicamos la ecuación de la recta, tendremos dos puntos descritos por pares (X, y) que uniremos con un un gráfico de lineas usando la función `plot` de matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.scatter(X_RM, y)\n",
    "\n",
    "xpoints = [min(X_RM), max(X_RM)]\n",
    "ypoints = model.predict(xpoints)\n",
    "\n",
    "plt.plot(xpoints, ypoints, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que los valores son altos (hasta 50) no debemos preocuparnos mucho por un pequeño error de -1.518.  \n",
    "Pero aplica sólo a la primera vivienda, ¿cómo evaluamos el error de todas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluando el modelo\n",
    "Podríamos promediar todos los errores, pero los que estén debajo de la resta serán **negativos** para solucionar esto podemos elevar cada error al cuadrado, sumar todos y dividir el resultado entre el número de errores.\n",
    "\n",
    "$$\\frac{1}{n} \\sum{(y_{r} - \\widehat{y} )^2}$$\n",
    "\n",
    "\n",
    "$\\widehat{y}$ se lee **y hat** (en español, *ye sombrero*) es el valor que predice el modelo, esto nos muestra que medimos la distancia vertical de cada punto a la recta para calcular el error. La recta que **mejor se ajusta** es aquella que **minimiza las distancias** hacia todos los puntos.\n",
    "\n",
    "Esta fórmula es una **métrica** conocida como **mean squared error** (**MSE** para los amigos) o error cuadrático promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = predicted_values\n",
    "\n",
    "squared_errors = (y_hat - y) ** 2\n",
    "mse = sum(squared_errors) / len(y)\n",
    "\n",
    "print(f\"MSE: {mse :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Es bastante alto!\n",
    "\n",
    "Si un error es alto, este al cuadrado es mucho más alto, y podemos observar **outliers** o valores extremos que se alejan bastante de la recta, sumándolos... tenemos el porqué ese error tan alto.  \n",
    "Es frecuente calcular el **square root of MSE (RMSE)** o raíz cuadrada del MSE para tener una mejor idea del error real, sin embargo este sigue siendo afectado por los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mse ** (1/2)\n",
    "print(f\"RMSE: {rmse :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mucho mejor :)\n",
    "\n",
    "Pero existe una métrica que no es afectada por outliers, **mean absolute error (MAE)** o error absoluto promedio, es otra solución para los errores negativos, quizá hayas pensado también en el valor absoluto.\n",
    "Por cierto, tanto MSE como MAE se pueden calcular con `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_hat, y) :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incluyendo más features\n",
    "¿Recuerdas que sklearn espera un array 2D? cada feature que incluímos es una columna más, y tendremos los siguientes cambios:\n",
    "- Entrenaremos una regresión lineal **múltiple**\n",
    "- el atributo `.coef_` del modelo tendrá n features, siempre los tuvo, pero sólo tomamos el primer valor ;)\n",
    "- es posible que mejore el modelo, si las features aportan a la predicción\n",
    "\n",
    "Incluyamos la octava feature: **DIS** que describe la \"distancia ponderada a cinco centros de empleo\", ambas features estarán en una lista.\n",
    "\n",
    "**TIP:** Si incluyes una sóla feature en la lista ya no necesitarás hacer el reshape a (-1, 1) ;D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas las filas, sexta y octava columna\n",
    "X_selected_features = X[:, [5, 7]]\n",
    "X_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos otro modelo\n",
    "model_selected_features = LinearRegression()\n",
    "\n",
    "# ¡ya no es necesario reshape!\n",
    "model_selected_features.fit(X_selected_features, y)\n",
    "\n",
    "print(\"Coeficientes: \", model_selected_features.coef_)\n",
    "\n",
    "# evaluemos\n",
    "y_hat = model_selected_features.predict(X_selected_features)\n",
    "print(f\"MAE: {mean_absolute_error(y_hat, y) :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Mejoró!\n",
    "\n",
    "Intenta cambiar las features o incluir más, pero no todas las combinaciones darán un mejor modelo, por razones que trataremos más adelante.  \n",
    "Tampoco podrás graficar en 2D si escoges 2 o más features, para ver cómo se ajustó la recta, pero siempre podras usar alguna métrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal múltiple\n",
    "Como mencionamos, el modelo cambia de nombre ahora permite aprender de múltiples features.  \n",
    "Un nuevo nombre conlleva una (casi) nueva ecuación:\n",
    "\n",
    "$y = a_1x_1 + a_2x_2 + ... + a_nx_n + b $\n",
    "\n",
    "+ n el número de features\n",
    "+ a es un vector de coeficientes\n",
    "+ x es el vector de cada feature\n",
    "+ b es el término independiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Es un buen modelo?\n",
    "Las métricas son útiles, pero pueden ser engañosas, debemos escoger la que se adecue al problema, no la que menor error tenga. Lo importante es preguntarte ¿debería tomar en cuenta los outliers?  \n",
    "La respuesta dependerá de los objetivos del modelo, y este dependerá de los datos.\n",
    "\n",
    "\n",
    "Las métricas suelen ser lo último que extraemos de un proyecto de machine learning, antes debemos [probarlo](./3_test_set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
