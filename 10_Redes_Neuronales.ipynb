{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3df6f-fe01-49b2-b100-5fd97754b4ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p datasets\n",
    "%cd datasets\n",
    "! wget -nc https://raw.githubusercontent.com/pablonoya/zigzag-ml/master/datasets/Iris.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ab46a-ded8-4c6a-8e0b-5cafcd4d9310",
   "metadata": {},
   "source": [
    "# Redes Neuronales Artificiales\n",
    "Quiero empezar con una cita del libro *Hands-On Machine Learning with Scikit-Learn, Keras and Tensorflow*\n",
    "> Los p치jaros nos inspiraron para volar, la Bardana inspir칩 el Velcro, y la naturaleza ha inspirado innumerables inventos m치s. Parece l칩gico, pues, fijarnos en la arquitectura del cerebro para inspirarnos en la construcci칩n de una m치quina inteligente.\n",
    ">\n",
    "> Aur칠lien G칠ron, 2019, p. 310\n",
    "\n",
    "Estas redes artificiales son a menudo representadas por **capas de neuronas totalmente conectadas entre s칤**, podemos distinguir tres partes:\n",
    "1. Capa de entrada\n",
    "2. Una o varias capas ocultas\n",
    "3. Capa de salida.\n",
    "\n",
    "![Red neuronal artificial](./img/10.1_Artificial_neural_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e428d-0886-4dad-9265-1682e487dcaf",
   "metadata": {},
   "source": [
    "## Implementaci칩n con Keras\n",
    "Este tipo de redes son denominadas *fully connected* y pueden implementarse como un modelo `Sequential` con capas `Dense`, porque son una secuencia de capas densamente conectadas 游땔.  \n",
    "Tomaremos ambos elementos del m칩dulo `keras` de tensorflow 2, que tiene subm칩dulos como `models` y `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f843abe-f6cf-4f3c-9577-a88e3e569328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo secuencial\n",
    "from tensorflow.keras.models import Sequential\n",
    "# capa densa\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997070e7-8f81-4c9d-bb22-eb6a7167b2aa",
   "metadata": {},
   "source": [
    "Podemos definir las capas del modelo pas치ndolas en una lista al momento de instanciarlo, cada capa `Dense` conecta las neuronas por nosotros, s칩lo debemos definir el n칰mero de neuronas en la primera, correspondiente a la capa de entrada, con el argumento `input_shape` el cual recibe una tupla, pero dejaremos la segunda dimensi칩n vac칤a.  \n",
    "Para las capas posteriores, no es necesario definir este argumento, es calculado a partir de la capa anterior 游땔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c177778-31e4-49f4-9d2b-28f46fa49a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(2,)),\n",
    "    Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed54627-027d-40ae-9faa-62b841c4635d",
   "metadata": {},
   "source": [
    "Podemos ver un resumen de la arquitectura de nuestra red con el m칠todo `summary` este nos muestra el tipo de capas, las shapes de salida, donde None significa un n칰mero variable, y el n칰mero de par치metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05184dd-b11d-4e14-acff-5e88a2409239",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530e66b-1187-42c8-8b7c-599d1d053035",
   "metadata": {},
   "source": [
    "Tambi칠n podemos instanciar nuestro modelo para a침adir despu칠s las capas con el m칠todo `add`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc99829-f18c-41d6-b6a5-8e47c832a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(3, input_shape=(2,)))\n",
    "model2.add(Dense(2, input_shape=(2,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687f6e7-9771-4bd0-a277-ce571686da97",
   "metadata": {},
   "source": [
    "Obteniendo el mismo resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f62385-1fa3-4c96-b455-411ab9b33048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2cf189-10cd-4ef5-83b3-b0c7cb0b392d",
   "metadata": {},
   "source": [
    "# Neurona biol칩gica, neurona artificial\n",
    "Las **neuronas artificiales** nacieron de la idea de **replicar las neuronas biol칩gicas**, estas **reciben un impulso por medio de sus dendritas y lo transmiten a trav칠s de su ax칩n** hacia otras neuronas, formando una red.\n",
    "\n",
    "![Neurona biol칩gica](img/10.2.1_Biological_neuron.png)\n",
    "\n",
    "De la misma manera, una neurona artificial **recibe la informaci칩n de otras neurona asign치ndoles pesos** o _weights_, realiza una **sumatoria de las entradas ponderadas**, y **pasa el resultado por una funci칩n de activaci칩n** para propagar una respuesta.\n",
    "\n",
    "![Neurona artificial](img/10.2.2_Artificial_neuron.png)\n",
    "\n",
    "Recuerdas el t칠rmino independiente?, tambi칠n conocido como *bias* y tambi칠n presente en las redes neuronales cumple la misma funci칩n de dotar de mayor libertad al ajuste de par치metros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd93eb-adbc-41b1-b61d-26bf38ba5c88",
   "metadata": {},
   "source": [
    "# Funci칩n de activaci칩n\n",
    "Cumple la tarea de romper la linealidad de las redes neuronales, podemos usar funciones como la sigmoide, pero la m치s utilizada es la funci칩n *Rectified Linear Unit* o **ReLU** para los amigos. Se define con una f칩rmula muy sencilla, la cual implementaremos.\n",
    "\n",
    "$$R(z) = max(0, z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4bb6c-e7e0-4632-b01f-3f2b7f0ae337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(z):\n",
    "    return np.max((0, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cb6fa-5611-4d18-9fc6-9aefc3f27b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xpoints = np.linspace(-1, 1, 11)\n",
    "ypoints = [relu(x) for x in xpoints]\n",
    "\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.grid()\n",
    "plt.ylim(-0.2, 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6469c5-5858-4b3f-9ad7-4384c61960f6",
   "metadata": {},
   "source": [
    "**Esta funci칩n se aplica entre capas**, a excepci칩n de la 칰ltima, cuya funci칩n de activaci칩n cambiar치 dependiendo de nuestra tarea:\n",
    "\n",
    "- Funci칩n **linear**, equivalente a no usar ninguna funci칩n, si deseamos realizar **regresi칩n**.\n",
    "- Funci칩n **sigmoide** si deseamos realizar **clasificaci칩n binaria**.\n",
    "- Funci칩n **softmax** para **clasificaci칩n m칰ltiple**.\n",
    "\n",
    "Adem치s el **n칰mero de neuronas en la capa de salida** depender치 de la tarea que busquemos resolver, siendo **s칩lo una para regresi칩n o clasificaci칩n binaria** y el **n칰mero de clases** para la **clasificaci칩n m칰ltiple**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c934b12-d3a2-47e6-a776-715b3aa238a1",
   "metadata": {},
   "source": [
    "# Clasificando Iris\n",
    "Veamos otra vez m치s nuestro dataset de Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736bd1e-2223-4f03-a21d-c77a428dfd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./datasets/Iris.csv')\n",
    "data.drop('Id', axis='columns', inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72656f-2a88-45af-a5be-55e3b6301c17",
   "metadata": {},
   "source": [
    "Ahora dividimos en features y labels, luego en conjuntos train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e100189-82e8-40c6-b59b-15af915b73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('Species', 'columns')\n",
    "\n",
    "# utilizaremos one-hot encoding\n",
    "y = pd.get_dummies(data['Species'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e477093-4c44-46bd-bf47-9dcfea0d8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79577742-2eaf-45ba-9ee8-f9c0099093f4",
   "metadata": {},
   "source": [
    "## Modelo: Red neuronal\n",
    "Tenemos 4 features, ese ser치 el n칰mero de neuronas en nuestra capa de entrada.  \n",
    "Para las capas ocultas, usualmente se recomienda usar potencias de 2, adem치s de seguir con la forma que vimos al principio lara que la red sea m치s grande en el centro, definamos 2 capas de 8 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de284524-f5a2-4be4-8309-6c4ba3930c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris = Sequential([\n",
    "    Dense(8, input_dim=4),\n",
    "    Dense(8, activation='relu'),\n",
    "    # capa de salida, activaci칩n softmax\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20689981-f9c4-436e-8e8d-14efc1424f80",
   "metadata": {},
   "source": [
    "## Configuraci칩n\n",
    "Mediante el m칠todo `compile` podemos definir opciones adicionales, **la funci칩n de costo es obligatoria**, definida por el par치metro `loss` siendo `\"categorical_crossentropy\"` para el caso de softmax.  \n",
    "\n",
    "Tambi칠n cambiaremos el **optimizador** por el [Descenso del gradiente estoc치stico](Descenso del gradiente estoc치stico), el cual intercambia la precisi칩n del gradiente por la velocidad, pues calcula el gradiente a partir de una muestra aleatoria de datos en lugar de utilizar todos, esta idea es bastante 칰til en datasets gigantes 游뱚. Podemos establecerlo con el par치metro `optimizer=\"sgd\"`.  \n",
    "\n",
    "Adem치s podemos incluir m칠tricas adicionales, el costo se nos mostrar치 por defecto, incluyamos la exactitud o `\"acc\"` dentro de una lista 游땏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdecf4b-310a-4914-a33d-5c9a11742102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d198b18-bcb1-4f0d-9fd0-baea01cdb7d8",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "Tambi칠n contamos con el m칠todo `fit` al igual que sklearn, pero debemos indicarle el n칰mero m치ximo de iteraciones o `epochs` y opcionalmente el `batch_size`, que indica el **tama침o de la muestra aleatoria** que usar치 para actualizar el gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c38f3-7d55-4c6d-851d-9fdb9bfabe29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_iris.fit(X_train, y_train, epochs=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c44a43-8db4-431b-8f89-f4258e8c5189",
   "metadata": {},
   "source": [
    "Para cada *epoch* tenemos 6 *batches*, $6 \\times 20 = 120$, el n칰mero de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11514d69-1c8b-47f6-a757-c8be2a553715",
   "metadata": {},
   "source": [
    "## Evaluaci칩n\n",
    "El modelo tiene un m칠todo `evaluate` que puede evaluar seg칰n las m칠tricas que definimos al configurar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48b069-c6c9-492b-b352-ac0bde4f4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicci칩n y evaluaci칩n\n",
    "y_hat = model_iris.predict(X_test)\n",
    "model_iris.evaluate(X_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746fa0f-bc56-4530-9f5f-8a247745c377",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "Cuando hablamos de *Deep Learning* o Aprendizaje profundo nos referimos al uso de redes neuronales para resolver tareas m치s complejas, estamos ante una **especializaci칩n** del *Machine Learning*\n",
    "\n",
    "![Deep learning dentro de ML](img/10.5_IA_ML_DL.png)\n",
    "\n",
    "Tareas como dotar a las m치quinas la capacidad de **reconocer d칤gitos escritos a mano** 九꽲잺游뱚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ceede5-abe5-4eb8-bdc1-d969c1fc6096",
   "metadata": {},
   "source": [
    "# Reconociendo d칤gitos\n",
    "MNIST es un dataset con una gran cantidad de d칤gitos escritos a mano, son 70 mil 游땸 en forma de im치genes de 28 x 28 pixeles.  \n",
    "Es toda una leyenda, por lo que muchas veces se utiliza como hola mundo 游땏 y podemos cargarlo gracias a keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69059efd-fdaa-467f-a6be-604cf91846bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e44a4-67ff-4cba-9407-e75c044fa449",
   "metadata": {},
   "source": [
    "La versi칩n de keras ya cuenta con los conjuntos de entrenamiento y prueba, devueltos por la funci칩n `load_data` con una estructura un poco extra침a para desempaquetar 游뱂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab4e39-08f7-4b50-958a-7526201b09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mnist.load_data()\n",
    "\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0f5d9-850a-4cda-81e1-1ac560dbb08a",
   "metadata": {},
   "source": [
    "Veamos el primer ejemplo de entrenamiento con `imshow` de matplotlib, el argumento `cmap=\"Greys\"` nos permite ver la imagen en escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57868dd-ad4a-450a-ae51-0c8fb866a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c930f-0bd5-4398-9d9b-85cf0395f980",
   "metadata": {},
   "source": [
    "Este es el n칰mero..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbefbf1-5436-4de9-a567-9b88b3bbbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709b00a-05c8-4c4f-bba0-6b93c87b2924",
   "metadata": {},
   "source": [
    "Adem치s, ya tenemos los datos como deber칤amos, en n칰meros 游댝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c92c3-0c54-44ef-b2f7-11e838ae4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742eca8-b7a3-4b69-aa41-52977aab425f",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "Tenemos **valores de 0 a 255**, los valores m치s altos son grises m치s oscuros. Pero **esta diferencia de valores puede dar problemas** con una red neuronal, por lo que un preprocesamiento com칰n es **dividirlos por 255** para dejarlos en un **rango de 0 a 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2139a-6b8b-4580-a733-8428b72916c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd290e-a304-4211-9070-bcb76f656768",
   "metadata": {},
   "source": [
    "Los labels est치n en un s칩lo n칰mero entero, pero deber칤an estar en One-hot encoding.  \n",
    "Por suerte to_categorical() de keras puede ayudarnos con eso 游땔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2f29c-be1a-4996-ad4f-fc11ab7f045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddeb4b-4389-4c67-bf0e-1989691c3056",
   "metadata": {},
   "source": [
    "## Arquitectura de la red\n",
    "Es bastante sencillo definir la capa de salida, tenemos d칤gitos del 0 a 9 y nuestra tarea es clasificaci칩n multiclase, tendremos una **capa de salida con 10 neuronas y la activaci칩n softmax**.\n",
    "\n",
    "La entrada es una **matriz de 28 x 28**, esto son 784 n칰meros, usaremos ese n칰mero de neuronas en la capa de entrada para esta red, pero antes debemos \"aplanar\" esta matriz para convertirla en un s칩lo vector de 784 n칰meros.\n",
    "\n",
    "![aplanar matriz](https://i.imgur.com/dDYphPB.png)\n",
    "\n",
    "Podemos lograr esto usando una capa `Flatten` de keras, que recibir치 un input shape de (28, 28).  \n",
    "Y para las **capas ocultas** puedes usar 1024 o 512 unidades 游땎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe755f-a503-42ba-a369-1ded11388f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "model_mnist = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(___, activation='relu'),\n",
    "    Dense(___, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc69d7-522c-4880-918b-854e393b09fa",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "Usaremos las mismas opciones que en el caso de las Iris, cambiando el **batch size** a 128, tambi칠n **se recomienda usar potencias de 2** para este argumento. En el caso anterior eleg칤 20 para dividir exactamente los 120 ejemplos de entrenamiento 游땙."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643d72c-78fa-4cb1-93a4-6d3cd5718031",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnist.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=['acc'])\n",
    "\n",
    "model_mnist.fit(X_train_scaled, y_train_cat, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c60e58-2c26-461f-ac52-63aedad13ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model_mnist.predict(X_test_scaled)\n",
    "model_mnist.evaluate(X_test_scaled, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471f5ee-5a1f-4ad6-9cec-9fc908a884ff",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "Muestra un d칤gito y del conjunto de prueba junto a la predicci칩n de la red neuronal 游땔."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40d9b7-1032-4c58-860d-83b1644a701a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb00b94-8241-40ad-b466-409fd5139dad",
   "metadata": {},
   "source": [
    "El n칰mero de capas ocultas, el n칰mero de neuronas por capa y el batch size son **hiperpar치metros** trata de ajustarlos para mejorar el rendimiento de la red que reconoce d칤gitos del mnist 游땙."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44470c09-2cf7-458d-9951-f32429a04789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51640b90-fa49-495f-ae39-d4128bde1a14",
   "metadata": {},
   "source": [
    "# Ep칤logo\n",
    "El *Deep Learning* es una de las 치reas que m치s crecimiento ha tenido en los 칰ltimos a침os, posibilita que las m치quinas sean **capaces de aprender tareas mucho m치s complejas, sobre im치genes, texto, audio e incluso video** 游뱚\n",
    "\n",
    "Tales cuestiones requieren de un amplio estudio, y de seguro est치s con muchas ganas de aprender 游땎.\n",
    "\n",
    "Esta colecci칩n de notebooks naci칩 del deseo de compartir las bases del *Machine Learning*, sobre las que puedes apoyarte siempre que lo requieras, mi mayor deseo es haberte transmitido el entusiasmo que tengo por esta 치rea y compartir un poco el c칩mo funciona 游뱂.\n",
    "\n",
    "춰Gracias por quedarte hasta el final! 游땕  \n",
    "Te deseo un feliz viaje por el mundo del Machine Learning 游땎."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
