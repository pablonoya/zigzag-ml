{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "! mkdir -p datasets\n",
    "%cd datasets\n",
    "! wget -nc https://raw.githubusercontent.com/pablonoya/zigzag-ml/master/datasets/housing.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¬øC√≥mo probamos un modelo?\n",
    "La mejor manera de probar un modelo es **utilizarlo el mundo real**, mandarlo a enfrentar la vida prediciendo nuevos datos que no haya visto durante su entrenamiento üòÉ.\n",
    "\n",
    "Obtener estos datos puede ser muy complicado, y si el modelo no rindiera bien tendremos que realizar ajustes como elegir diferentes *features* y volver a conseguir m√°s datos.\n",
    "\n",
    "Pero esta sigue siendo la mejor manera de evaluar, vamos a enga√±ar al modelo dici√©ndole que **no tenemos todo el dataset** üòè.  \n",
    "**Reservaremos una parte** que no utilizar√° durante el entrenamiento, el **test set** o conjunto de prueba.  \n",
    "Por supuesto, el otro conjunto ser√° el **training set** o conjunto de entrenamiento.\n",
    "\n",
    "![training_test_set](img/3.1_train_test_set.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando training y test\n",
    "Con frecuencia, se divide el dataset en **80% para training y 20% para test**, y particiones de 70-30 o 60-40 tambi√©n son habituales, dependiendo a la cantidad de ejemplos en nuestro dataset y qu√© tan preciso deseamos que sea.\n",
    "\n",
    "Pero **antes debemos mezclarlo** como una baraja de naipes üÉè, ¬øpor qu√©? porque necesitamos una **muestra aleatoria que represente en general** a todo el conjunto de datos.  \n",
    "Imaginemos que los datos fueron tomados por zonas y en orden, la √∫ltima parte podr√≠an ser las viviendas de una s√≥la zona, y esta podr√≠a **faltar en el entrenamiento**. Entonces nuestro modelo **no aprender√≠a** de ella.\n",
    "\n",
    "Esta diversidad de datos es importante, si faltar√° cualquier tipo de ejemplos, el modelo simplemente no la conocer√≠a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primero mezclamos\n",
    "Sea n el tama√±o del dataset.  \n",
    "Creamos un array de 0 a n-1 que contiene los **indices**, lo mezclamos al azar y reemplazamos **X** e **y** con los **indices desordenados**, es importante que sean los **mismos indices**, cada **X** mantiene su correspondiente **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_housing = pd.read_csv('./datasets/housing.csv')\n",
    "\n",
    "X = data_housing['median_income']\n",
    "y = data_housing['median_house_value']\n",
    "\n",
    "# ¬øcu√°ntos datos tenemos?\n",
    "n = len(X)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# array de 0 a n-1\n",
    "indices = np.arange(n)\n",
    "\n",
    "print(indices[:5], \"...\", indices[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desordenamos\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[:5], \"...\")\n",
    "\n",
    "# reemplazamos\n",
    "X = X[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta de nuevo la celda anterior, para comprobar la aleatoriedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entonces dividimos  \n",
    "Dividamos en 80-20, necesitamos el indice que marque d√≥nde se ubica este 80%  \n",
    "Tanto **train set** como **test set** son t√©rminos que agrupan a las *features* y *labels*, por lo que compartir√°n √≠ndices en sus respectivos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el √≠ndice debe ser entero\n",
    "training_size = int(n * 0.8)\n",
    "\n",
    "# seleccionamos el primer 80%\n",
    "X_train = X[:training_size]\n",
    "y_train = y[:training_size]\n",
    "\n",
    "# y el 20% restante\n",
    "X_test = X[training_size:]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print(f\"N√∫mero de datos de entrenamiento: {len(X_train)}, y de prueba: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Veamos ambos conjuntos** con gr√°ficas de dispersi√≥n, como vimos en el ejemplo de la recta, podemos sobreponer gr√°ficas llam√°ndolas una despu√©s de otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# primero entrenamiento pues es un conjunto m√°s grande\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test, y_test)\n",
    "\n",
    "plt.title(\"Conjuntos de entrenamiento y prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos conjuntos son representativos, ¬øverdad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando, probando\n",
    "Primero entrenamos **s√≥lo y √∫nicamente en el train set**.  \n",
    "\n",
    "Luego predecimos y calculamos el **MSE** usando los datos no vistos, el **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#reshape again\n",
    "X_train_2D = X_train.values.reshape(-1, 1)\n",
    "X_test_2D = X_test.values.reshape(-1, 1)\n",
    "\n",
    "# entrenamiento\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_2D, y_train)\n",
    "\n",
    "# prueba!\n",
    "y_hat = model.predict(X_test_2D)\n",
    "print(f\"MSE (test set) {mean_squared_error(y_hat, y_test) :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta cantidad es m√°s fiable, como el modelo no conoce estos datos, podemos decir que  nuestro modelo ha enfrentado la vida real üòÉ (siempre que tus datos sean reales üòÖ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar en entrenamiento y prueba\n",
    "Sci-kit learn es bastante √∫til para realizar machine learning por su **colecci√≥n de funciones** y `train_test_split` nos permite realizar justo lo que acabamos de ver. Recibe como argumentos las *features*, *labels* y el tama√±o, en una escala de 0 a 1, del conjunto de prueba en `test_size`, o el de entrenamiento en `train_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.2)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "Calcula el MSE en el conjunto de entrenamiento, ¬øeste sube es mejor o pero que en el de prueba?, ¬øpor qu√© crees que sea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo mismo pero con otra variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¬°Importante!**  \n",
    "No es bueno que tus datos aleatorios var√≠en tanto, inclu√≠r o no ciertos datos podr√≠a afectar a tus pruebas y hacer que los resultados no sean [reproducibles](https://es.wikipedia.org/wiki/Reproducibilidad_y_repetibilidad), esto es, que sean diferentes cada vez que los ejecutas.  \n",
    "Puedes cuidarte de esto usando una  **implementando una** [semilla aleatoria](https://es.wikipedia.org/wiki/Semilla_aleatoria), crea una para este cap√≠tulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def√≠ne la semilla aparte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y entonces realiza tus pruebas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoremos el modelo\n",
    "Con las pruebas realizadas es natural que busquemos alguna manera de **mejorar los resultados**, y existe algo que puede ser mejor que elegir y combinar features: crear [nuevas features](4_Creando_features.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
