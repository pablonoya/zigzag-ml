{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n\n",
    "En realidad no estamos tan listos, faltan ciertos detalles.\n",
    "Primero respondamos a la pregunta del cap√≠tulo anterior, marcando la columna Species con **1** en el caso de **Iris-setosa** y **0** de lo contrario.\n",
    "\n",
    "Si usamos alguna **condici√≥n** con una tabla o columna de pandas tendremos un objeto [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html) de pandas con valores **verdero-falso** en las **filas** que cumplan la condici√≥n.\n",
    "\n",
    "Esto es como un array que tiene √≠ndices, cuando seleccionamos **una sola columna** de un DataFrame tambi√©n tenemos un objeto **Series**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# al dataset original le quitamos la columna Id\n",
    "data = pd.read_csv(\"datasets/Iris.csv\")\n",
    "df = data.drop(columns=\"Id\")\n",
    "\n",
    "setosa = df[\"Species\"] == \"Iris-setosa\"\n",
    "setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora **reemplazamos** la columna Species por esta variable, pero convertida a **n√∫meros** mediante su m√©todo `astype`.   \n",
    "\n",
    "Las primeras o √∫ltimas filas nos mostrar√°n s√≥lo valores de 1 o 0, respectivamente, tomemos una **muestra** de valores al azar con el m√©todo `sample` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species'] = setosa.astype(int)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificaci√≥n Binaria\n",
    "La predicii√≥n se limita a **dos** valores, el t√©rmino \"binario\" se debe a ello.  \n",
    "Veamos la **relaci√≥n** entre el **ancho del s√©palo** con nuestro **target**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(df['SepalWidthCm'], df['Species'])\n",
    "plt.xlabel(\"Ancho del s√©palo\")\n",
    "plt.ylabel(\"¬øEs setosa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustar una **recta** no bastar√≠a, deja muchos puntos fuera ‚òπ.\n",
    "\n",
    "Veamos si una **curva** lo hace mejor, podemos usar **Series** o **DataFrames** en nuestro modelo, pero deben estar en 2D porque sklearn espera que as√≠ sea. El mismo truco de seleccionar usando una **lista con una sola columna** funciona üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# datos\n",
    "X, y = df[['SepalWidthCm']], df[['Species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora toca entrenar, **elige cualquier modelo** de los que vimos para **regresi√≥n lineal**.  \n",
    "Tambi√©n debes **transformar** las features a **polinomiales**, te sugiero usar un **grado** mayor a 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ___\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# modelo\n",
    "poly = PolynomialFeatures(degree=___, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "model = ___\n",
    "model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los resultados, toma en cuenta que `X_train` es un DataFrame, por esto tiene sus propios m√©todos `min` y `max` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gr√°fica\n",
    "xpoints = np.linspace(X_train.min(), X_train.max(), num=40)\n",
    "ypoints = model.predict( poly.transform(xpoints) )\n",
    "\n",
    "plt.scatter(X_train, y_train, color='gray')\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.xlabel(\"Ancho del s√©palo\")\n",
    "plt.ylabel(\"¬øEs setosa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoide\n",
    "Exi**s**te una curva que encaja muy bien con este problema, tiene forma de **S** y va en un rango de 0 a 1, pero **nunca exactamente 0 o 1**, y su f√≥rmula es:\n",
    "\n",
    " $\\sigma(x) = \\dfrac{1}{1 + e^{-x}}$\n",
    "\n",
    "Donde $\\sigma$ se lee *sigma*, $e$ es el [n√∫mero](https://es.wikipedia.org/wiki/N%C3%BAmero_e), y $x$ es un punto cualquiera, podr√≠a ser de nuestra **feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpoints = np.linspace(-10, 10, num=50)\n",
    "\n",
    "# np.exp(x) equivale a e^x\n",
    "ypoints = 1 / (1 + np.exp(-xpoints))\n",
    "\n",
    "plt.plot(xpoints, ypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n Log√≠stica\n",
    "Nuevo objetivo:  hallar la **sigmoide** que mejor se **ajuste** a los datos cambiando los ¬øpar√°metros?\n",
    "\n",
    "La sigmoide no tiene **par√°metros** que ajustar, **primero** tendremos una **regresi√≥n lineal** guardando los resultados:  \n",
    "$z = X\\theta$\n",
    "\n",
    "Luego utilizamos la **sigmoide**:  \n",
    "$\\hat{y} = \\sigma(z)$\n",
    "\n",
    "Esta idea ser√° importante m√°s adelante üòâ \n",
    "\n",
    "Por √∫ltimo definiremos un **umbral**, digamos 0.5, si $\\sigma(z)$ es **mayor** a este la predicci√≥n ser√° **1** y ser√° **0** si es **menor** a 0.5\n",
    "\n",
    "De todo esto se encargar√° `LogisticRegressor` de sklearn, pero este modelo espera que `y` sea **1D** asi que convertiremos este **DataFrame** a un **array de numpy** y le aplicaremos `reshape` a una sola dimensi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
    "\n",
    "xpoints = np.linspace(X_train.min(), X_train.max(), num=50)\n",
    "ypoints = model.predict(xpoints)\n",
    "\n",
    "plt.scatter(X_train, y_train, color=\"gray\")\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.xlabel(\"Ancho del s√©palo\")\n",
    "plt.ylabel(\"¬øEs setosa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy bien, quiz√° demasiado bien... pero es porque sklearn retorna un resultado **entero** por defecto.\n",
    "\n",
    "Por cierto, el nombre viene de la **log√≠stica** que maquinamos para lograr la clasificaci√≥n binaria üòé  \n",
    "$\\cdots$\n",
    "\n",
    "No, en realidad viene de la funci√≥n [logit](https://es.wikipedia.org/wiki/Logit) que es la base para su **funci√≥n de costo**:\n",
    "\n",
    "$J(\\theta) = -y\\ log(\\hat{y}) + (1-y)\\ log(1 - \\hat{y})$\n",
    "\n",
    "Esta expresi√≥n encierra nuestras **dos** posibles **respuestas**, nota que tienen complementos en forma de (1-y).\n",
    "\n",
    "Si $y=0$ tenemos:  \n",
    "$-0\\ log(\\hat{y}) - (1-0)\\ log(1 - \\hat{y})$  \n",
    "$= -log(1 - \\hat{y})$\n",
    "\n",
    "Si $y=1$ tenemos:  \n",
    "$\\ -log(\\hat{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos ambas en un rango de 0 a 1, pero **no exactamente 0 o 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpoints = np.linspace(0.01, 0.99, num=50)\n",
    "\n",
    "plt.plot(xpoints, -np.log(1 - xpoints), label=\"y = 0\")\n",
    "plt.plot(xpoints, -np.log(xpoints), label=\"y = 1\")\n",
    "plt.xlabel(\"ye sombrerito\")\n",
    "plt.ylabel(\"Costo\")\n",
    "\n",
    "plt.legend(loc=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la l√≠nea **y = 0**, tenemos menor costo si nos **acercamos a 0**, pues tambien nos acercar√≠amos a la respuesta correcta.\n",
    "\n",
    "Para el otro caso, tenemos la situaci√≥n contraria siendo **menor** el costo **cerca a 1**.\n",
    "\n",
    "Recuerda que **s√≥lo una de las funciones** es utilizada, dependiendo del **valor de y**.\n",
    "\n",
    "Nota que la funci√≥n es m√°s **empinada** cuanto **mayor** sea el **costo**, esto significa que **penaliza** m√°s las respuestas **incorrectas**, adem√°s es **convexa** pues s√≥lo tiene un m√≠nimo üòÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respondiendo la pregunta\n",
    "Para responder mejor, entrena el modelo con **todas** las features, **completa el c√≥digo** üòÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todas las features\n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "y = df['___']\n",
    "\n",
    "X_train, ___, y_train, ___ = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Lo___\n",
    "model.fit(___, ___)\n",
    "\n",
    "# ¬øes setosa u otra cosa?\n",
    "model.predict([[5.81, 3.05, 4.9, 2.11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando\n",
    "Como tenemos s√≥lo dos posibles respuestas, desearemos ver cu√°ntas veces **acertamos**, m√°s bien, el **porcentaje de aciertos**.\n",
    "\n",
    "Esto se conoce como **exactitud** y usando `accuracy_score` lo sabremos en un rango de 0 a 1, esta vez **s√≠** exactamente 0 o 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "accuracy_score(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La exactitud es **enga√±osa**, no te f√≠es s√≥lo de ella üòÑ en especial en **datasets no balanceados**.\n",
    "\n",
    "Para algunos datasets pueden ser dif√≠cil conseguir casos en la una **proporci√≥n similar**, un cl√°sico ejemplo:  \n",
    "Quieres detectar si hubo **fraude** en transacciones bancarias, pero la mayor√≠a **no son fraudulentas** (o eso espero)\n",
    "\n",
    "Este simple modelo puede **alcanzar gran exactitud**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelin():\n",
    "    def predict(X):\n",
    "        return [False] * len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que solo el **10%** de tu test set tiene **transacciones fraudulentas**, evaluemos a model√≠n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.random.randn(10)\n",
    "test_targets = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "pred_targets = modelin.predict(test_set)\n",
    "accuracy_score(pred_targets, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Genial!, model√≠n detecta el fraude con un **90%** de ...por eso digo que es **enga√±osa** ‚òπ\n",
    "\n",
    "Pero la idea base se mantiene saber la **cantidad de aciertos y fallas** entre la **predicci√≥n** del modelo y las **respuestas**, con esto podemos construir **cuatro casos**:\n",
    "\n",
    "+ La respuesta es 1 el modelo predijo 1 üòÑ\n",
    "+ La respuesta era 1 el modelo predice 0 ‚òπ\n",
    "+ Respuesta real 0, modelo predice 0 üòÑ\n",
    "+ Respuesta 0, modelo predice 1 ‚òπ\n",
    "\n",
    "Un poco... **confuso**, ¬øverdad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusi√≥n\n",
    "Podemos agrupar los casos en una matriz de dos filas y dos columnas de 0 y 1:\n",
    "\n",
    "![conf](./img/7.5_confussion_matrix.png)\n",
    "\n",
    "**Positivo** o **negativo** nos indicar√° la respuesta **predicha**, y ser√° **verdadero** o **falso** si es o no **igual a la real**.  \n",
    "Usaremos los t√©rminos en ingl√©s, pero s√≥lo con sus iniciales: *True Positive* ser√° **TP**, *False Negative*, **FN**.\n",
    "\n",
    "Las celdas de la matriz contienen la **cantidad de cada caso**, por esto la **suma** de todas las celdas resulta en el **total** de datos que usamos para calcularla.\n",
    "\n",
    "Con la matriz podemos calcular dos m√©tricas que se **compensan** entre s√≠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "Cuya f√≥rmula es:\n",
    "\n",
    "$precision = \\dfrac{TP}{TP + FP}$\n",
    "\n",
    "S√≥lo toma en cuenta **positivos, reales y predichos**, para responder la pregunta:  \n",
    "> De todos los positivos, ¬øcu√°ntos lo son realmente?  \n",
    "\n",
    "Esto es util para reducir falsos positivos, mientras menos sean, m√°s alta ser√° la precision.  \n",
    "En nuestro caso, un FP ser√≠a:\n",
    "> El modelo predijo que s√≠ hubo fraude, pero no lo hubo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "Cuya f√≥rmula es:\n",
    "\n",
    "$recall = \\dfrac{TP}{TP + FN}$\n",
    "\n",
    "Y toma en cuenta la **fila** de **positivos reales** para preguntar:\n",
    "> ¬øCu√°ntos positivos fueron predichos correctamente?\n",
    "\n",
    "Es util para minimizar un FN:\n",
    "> El modelo predijo que no hubo fraude, pero s√≠ lo hubo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ambos se compensan, debemos elegir cu√°l **penalizar m√°s** para reducirlo.  \n",
    "> ¬øEs peor dar una **falsa alarma** o **dejar pasar** un fraude?\n",
    "\n",
    "Podemos calcular todo lo visto usando `confusion_matrix`, `precision_score` y `recall_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "print(confusion_matrix(test_targets, pred_targets))\n",
    "\n",
    "print(\"Precision:\", precision_score(test_targets, pred_targets))\n",
    "print(\"Recall:\", recall_score(test_targets, pred_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una advertencia por la divisi√≥n entre 0, ¬°no tenemos **ning√∫n** positivo! y s√≥lo mirando la matriz de confusi√≥n podemos intuir \"algo anda mal\".\n",
    "\n",
    "Quiz√° alguna vez nos interese encontrar un **balance entre precision y recall**, podemos calcular esto usando `f1_score` cuya f√≥rmula es:\n",
    "\n",
    "$F1 = 2*\\dfrac{precision*recall}{precision+recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalua el modelo\n",
    "Te animo a que evalues nuestro **modelo de iris setosa**, comienza mirando la **matriz de confusi√≥n** üòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_hat, )\n",
    "\n",
    "# precision_score()\n",
    "# recall_score()\n",
    "# f1_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pudimos ver, la clasificaci√≥n es un mundo un poco distinto, pero seguimos dentro del **aprendizaje supervisado** porque tenemos features y targets.\n",
    "\n",
    "Y no acaba aqu√≠, tambi√©n podemos distinguir entre [varias clases](8_clasificacion_multiclase)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
