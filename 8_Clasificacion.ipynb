{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n Binaria\n",
    "Respondamos a la pregunta del cap√≠tulo anterior, marcando la columna \"Species\" con **1** en el caso de **Iris-setosa** y **0** de lo contrario.  \n",
    "Esta es una **nueva tarea** o *task*, en la cual buscamos **distinguir si un ejemplo pertenece o no a una determinada clase**. \n",
    "\n",
    "Podemos utilizar una **condici√≥n en una columna** del DataFrame, la de \"Species\" en este caso,  el resultado ser√° un objeto [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html) de pandas con valores **verdero-falso** en las **filas** que cumplan la condici√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"datasets/Iris.csv\")\n",
    "\n",
    "# mantenemos los datos en la variable original\n",
    "df = data.drop(columns=\"Id\")\n",
    "\n",
    "is_setosa = df[\"Species\"] == \"Iris-setosa\"\n",
    "is_setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora **reemplazamos la columna** por esta variable, convertida a **enteros** usando el m√©todo `astype`.   \n",
    "\n",
    "Las primeras o √∫ltimas filas nos mostrar√°n s√≥lo valores de 1, porque el dataset est√° ordenado seg√∫n las especies y Setosa es la primera.  \n",
    "Tomemos una **muestra** de cinco valores al azar con el m√©todo `sample` para verificar que existen valores enteros üòÑ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species'] = is_setosa.astype(int)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificaci√≥n Binaria\n",
    "La predicii√≥n se limita a **dos** valores, el t√©rmino \"binario\" se debe a ello.  \n",
    "Veamos la **relaci√≥n** entre el **ancho del s√©palo** con nuestro **target**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(df['SepalWidthCm'], df['Species'])\n",
    "plt.xlabel(\"Ancho del s√©palo\")\n",
    "plt.ylabel(\"¬øEs setosa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustar una **recta** no bastar√≠a, deja muchos puntos fuera ‚òπ.\n",
    "\n",
    "Veamos si una **curva** lo hace mejor, podemos usar **Series** o **DataFrames** en nuestro modelo, pero deben estar en 2D porque sklearn espera que as√≠ sea. El mismo truco de seleccionar usando una **lista con una sola columna** funciona üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# datos\n",
    "X, y = df['SepalWidthCm'], df['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values.reshape(-1, 1), y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora toca entrenar, **elige cualquier modelo** de los que vimos para **regresi√≥n lineal**.  \n",
    "Tambi√©n debes **transformar** las features a **polinomiales**, te sugiero usar un **grado** mayor a 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# modelo\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los resultados, toma en cuenta que `X_train` es un DataFrame, por esto tiene sus propios m√©todos `min` y `max` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gr√°fica\n",
    "xpoints = np.linspace(X_train.min(), X_train.max(), num=40)\n",
    "xpoints_poly = poly.transform(xpoints.reshape(-1, 1))\n",
    "ypoints = model.predict(xpoints_poly)\n",
    "\n",
    "plt.scatter(X_train, y_train, color='gray')\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.xlabel(\"Ancho del s√©palo\")\n",
    "plt.ylabel(\"¬øEs setosa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por mucho que incrementemos el grado no llegaremos a una curva convincente, al menos no con un modelo lineal ü§î."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoide\n",
    "Exi**S**te una curva que encaja muy bien con este problema, tiene forma de **S** y va en un rango de 0 a 1, justo lo que necesitamos, aunque **nunca llega exactamente a 0 o 1**, su f√≥rmula es:\n",
    "\n",
    " $\\sigma(x) = \\dfrac{1}{1 + e^{-x}}$\n",
    "\n",
    "Donde $\\sigma$ es la letra *sigma*, $e$ es el [n√∫mero e](https://es.wikipedia.org/wiki/N%C3%BAmero_e), y $x$ es un punto cualquiera, podr√≠a ser de nuestra **feature** o un rango de valores.  \n",
    "Definamos esto √∫ltimo para graficarla üòâ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpoints = np.linspace(-10, 10, num=50)\n",
    "\n",
    "# np.exp(x) equivale a e^x\n",
    "ypoints = 1 / (1 + np.exp(-xpoints))\n",
    "\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('sigma(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una curva que bien podr√≠a ajustarse a los datos, si la utilizamos tenemos un **nuevo modelo** conocido como..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi√≥n Log√≠stica\n",
    "Nuevo objetivo:  hallar la **sigmoide** que mejor se **ajuste** a los datos cambiando los ¬øpar√°metros?\n",
    "\n",
    "La sigmoide no tiene **par√°metros** que podamos ajustar, por lo que **primero definimos una regresi√≥n lineal** guardando los resultados en una variable:\n",
    "\n",
    "$z = X\\theta$\n",
    "\n",
    "Entonces, le aplicamos una **transformaci√≥n no lineal**, la **sigmoide**:  \n",
    "$\\hat{y} = \\sigma(z)$\n",
    "\n",
    "> Esta idea ser√° muy importante m√°s adelante üòâ. \n",
    "\n",
    "Por √∫ltimo, definiremos un **umbral**, pongamos 0.5. Si $\\sigma(z)$ es **mayor al umbral**, la predicci√≥n ser√° **1** y ser√° **0 de lo contrario**.\n",
    "\n",
    "De todo esto se encargar√° `LogisticRegressor` de sklearn, pero este modelo espera que `y` sea **1D** asi que convertiremos este **DataFrame** a un **array de numpy** y le aplicaremos `reshape` a una sola dimensi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_logistic = LogisticRegression()\n",
    "model_logistic.fit(X_train, y_train)\n",
    "\n",
    "xpoints = np.linspace(X_train.min(), X_train.max(), num=50)\n",
    "ypoints = model_logistic.predict(xpoints.reshape(-1, 1))\n",
    "\n",
    "plt.scatter(X_train, y_train, color=\"gray\")\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.xlabel(\"Ancho del s√©palo\")\n",
    "plt.ylabel(\"¬øEs setosa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Muy bien, quiz√° demasiado bien... porque sklearn retorna un **n√∫mero entero, 0 o 1** por defecto.\n",
    "\n",
    "Por cierto, el nombre viene de la **log√≠stica** que maquinamos para lograr la clasificaci√≥n binaria üòé  \n",
    "$\\cdots$\n",
    "\n",
    "No, en realidad viene de la funci√≥n [logit](https://es.wikipedia.org/wiki/Logit) que es la base para su **funci√≥n de costo**:\n",
    "\n",
    "$J(\\theta) = -y\\ log(\\hat{y}) + (1-y)\\ log(1 - \\hat{y})$\n",
    "\n",
    "Esta expresi√≥n encierra nuestras **dos posibles respuestas**, nota que tienen complementos en forma de $(1-y)$.\n",
    "\n",
    "Si $y=0$ tenemos:  \n",
    "$-0\\ log(\\hat{y}) - (1-0)\\ log(1 - \\hat{y})$  \n",
    "$= -log(1 - \\hat{y})$\n",
    "\n",
    "Si $y=1$ tenemos:  \n",
    "$\\ -log(\\hat{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Grafiquemos ambas en un rango de 0 a 1, pero **no exactamente 0 o 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhatpoints = np.linspace(0.001, 0.999, num=75)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(12, 5))\n",
    "# fig.ylabel(\"Costo\")\n",
    "plt.suptitle(\"Comparaci√≥n de respuestas\")\n",
    "\n",
    "ax1.plot(yhatpoints, -np.log(yhatpoints))\n",
    "ax2.plot(yhatpoints, -np.log(1 - yhatpoints), 'orange')\n",
    "\n",
    "ax1.set(xlabel=\"y_hat\", ylabel=\"Costo\", title=\"y=1\")\n",
    "ax2.set(xlabel=\"y_hat\", ylabel=\"Costo\", title=\"y=0\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Para el caso l√≠nea **y = 1**, tenemos menor costo si **la predicci√≥n se acerca a 1**, porque nos acercar√≠amos a la respuesta correcta.  \n",
    "Para el otro caso, tenemos la situaci√≥n contraria siendo **menor el costo cuando la predicci√≥n es 0**.\n",
    "\n",
    "Recuerda que **s√≥lo una de las funciones** es utilizada, **dependiendo del valor de y**, nuestro label.\n",
    "\n",
    "Nota que la funci√≥n es **m√°s empinada cuanto mayor sea el **costo**, esto significa que **penaliza m√°s las respuestas incorrectas**, adem√°s es **convexa** pues s√≥lo tiene un m√≠nimo üòÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y \\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Respondiendo la pregunta\n",
    "Para responder mejor, entrena el modelo con **todas** las features, **completa el c√≥digo** üòÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todas las features\n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "y = df['___']\n",
    "\n",
    "X_train, ___, y_train, ___ = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Log___\n",
    "model.fit(___, ___)\n",
    "\n",
    "# ¬øes setosa u otra cosa?\n",
    "model.predict([[5.81, 3.05, 4.9, 2.11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluando\n",
    "Como tenemos s√≥lo dos posibles respuestas, desearemos ver el **porcentaje de veces que el modelo acert√≥** la respuesta correcta.\n",
    "\n",
    "Esto se conoce como **exactitud** y utilizando la funci√≥n `accuracy_score` lo podemos calcular en un rango de 0 a 1, representando la escala de 0 a 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "accuracy_score(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "La exactitud es **enga√±osa**, no te f√≠es s√≥lo en esta m√©trica ü§® en especial para **datasets no balanceados**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets no balanceados\n",
    "Para algunos datasets pueden ser dif√≠cil **conseguir etiquetas positivas y negativas una proporci√≥n similar**, veamos un cl√°sico ejemplo:  \n",
    "Quieres detectar **si hubo o no alg√∫n fraude** en transacciones bancarias, pero resulta que la mayor√≠a de transaccciones **no son fraudulentas** (o eso espero üòÖ).\n",
    "\n",
    "Este simple modelo puede **alcanzar gran exactitud**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class modelin():\n",
    "    def predict(X):\n",
    "        return [False] * len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Supongamos que solo el **10%** de tu test set tiene **transacciones fraudulentas**, evaluemos a model√≠n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features = np.random.randn(10)\n",
    "test_targets = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "pred_targets = modelin.predict(test_features)\n",
    "accuracy_score(pred_targets, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "¬°Genial!, model√≠n detecta el fraude con un **90%** de preci... por eso digo que es **enga√±osa** ‚òπ\n",
    "\n",
    "Pero la idea base se mantiene saber el **porcentaje de aciertos y fallas** entre la **predicci√≥n** del modelo y las **respuestas**, con esta idea podemos **distinguir cuatro casos**:\n",
    "\n",
    "+ La respuesta es 1 el modelo predijo 1 üòÑ\n",
    "+ La respuesta era 1 el modelo predice 0 ‚òπ\n",
    "+ Respuesta real 0, modelo predice 0 üòÑ\n",
    "+ Respuesta 0, modelo predice 1 ‚òπ\n",
    "\n",
    "Un poco... **confuso**, ¬øverdad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Matriz de Confusi√≥n\n",
    "Podemos agrupar los casos en una matriz de dos filas y dos columnas de 0 y 1:\n",
    "\n",
    "![conf](./img/7.5.2_confussion_matrix.png)\n",
    "\n",
    "**Positivo** o **negativo** nos indicar√° la respuesta **predicha**, y ser√° **verdadera si es igual a la respuesta y falsa de lo contrario**. La matriz puede verse diferente seg√∫n la fuente que consultes, esta gr√°fica coincide con la matriz que genera sklearn pero los conceptos siempre se mantendr√°n.\n",
    "\n",
    "Usaremos los t√©rminos en ingl√©s, pero s√≥lo con sus iniciales: *True Positive* ser√° **TP**, *False Negative* ser√° **FN**, etc.\n",
    "\n",
    "Las celdas de la matriz contienen la **cantidad de cada caso**, por esto la **suma de todas las celdas es igual al total de datos** en el conjunto que usamos para calcularla, el cual deber√≠a ser el *test set*.\n",
    "\n",
    "Con la matriz podemos calcular dos m√©tricas que se **compensan** entre s√≠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Precision\n",
    "Cuya f√≥rmula es:\n",
    "\n",
    "$precision = \\dfrac{TP}{TP + FP}$\n",
    "\n",
    "S√≥lo toma en cuenta **positivos, reales y predichos**, para responder la pregunta:  \n",
    "> De todos los positivos, ¬øcu√°ntos lo son realmente?  \n",
    "\n",
    "Esto es util para reducir falsos positivos, mientras menos sean, m√°s alta ser√° la precision.  \n",
    "En el caso de la detecci√≥n de fraudes, un ejemplo ser√≠a:\n",
    "> El modelo predijo que s√≠ hubo fraude, pero no lo hubo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Recall\n",
    "Cuya f√≥rmula es:\n",
    "\n",
    "$recall = \\dfrac{TP}{TP + FN}$\n",
    "\n",
    "Y toma en cuenta la **fila** de **positivos reales** para preguntar:\n",
    "> ¬øCu√°ntos positivos fueron predichos correctamente?\n",
    "\n",
    "Es util para minimizar un FN:\n",
    "> El modelo predijo que no hubo fraude, pero s√≠ lo hubo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Como ambos se compensan, debemos elegir cu√°l **penalizar m√°s** para reducirlo.  \n",
    "> ¬øEs peor dar una **falsa alarma** o **dejar pasar** un fraude?\n",
    "\n",
    "Podemos calcular todo lo visto usando `confusion_matrix`, `precision_score` y `recall_score` de `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "print(confusion_matrix(test_targets, pred_targets))\n",
    "\n",
    "print(\"Precision:\", precision_score(test_targets, pred_targets))\n",
    "print(\"Recall:\", recall_score(test_targets, pred_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Tenemos una advertencia por la divisi√≥n entre 0 porque ¬°no tenemos **ning√∫n positivo**!, mirando la matriz de confusi√≥n podemos intuir que algo anda mal üëÄ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### F1 Score\n",
    "Quiz√° alguna vez nos interese encontrar un **balance entre precision y recall**, podemos calcular esto usando la m√©trica `f1_score` cuya f√≥rmula es:\n",
    "\n",
    "$F1 = 2*\\dfrac{precision*recall}{precision+recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejercicios\n",
    "Eval√∫a nuestro **modelo de iris setosa**, comienza obteniendo la **matriz de confusi√≥n** üòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval√∫a sobre el test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obt√©n las m√©tricas de precision, recall y f1 score usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Como pudimos ver, la clasificaci√≥n es un mundo un poco distinto, pues tuvimos que a√±adir una nueva funci√≥n que transformaci√≥n no lineal a nuestra recta üò±.\n",
    "\n",
    "Pero este **tipo de tarea** no acaba aqu√≠, tambi√©n podemos distinguir entre [varias clases](9_Clasificacion_multiclase.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
